{
  "RELEASENOTE.html": {
    "href": "RELEASENOTE.html",
    "title": "Version Notes (Current Version: v2.5.2) | DocFX website",
    "keywords": "Version Notes (Current Version: v2.5.2) v2.5.2 Fix error message for invalid file link. v2.5.1 Support attribute filter to filter out attributes. Support choosing git URL pattern. ( https://github.com/dotnet/docfx/issues/677 ) Fix bug for line number is 0. v2.5 Add source file and line number for warning invalid file/uid link. Fix bugs in markdown table. v2.4 Update default template theme. Fix resolving properties for swagger. Fix bugs in markdown. Fix id in title (following GitHub rule). Fix strikeout not work in dfm. Fix tight list item behavior. Fix line number in table. v2.3 Support emoji in markdown content. Upgrade yamldotnet to 3.9. Refine markdown validation. Support separated meta json file. Change hightlight.js theme to github-gist . Support '.json' as supported swagger file extension. Support topicHref and tocHref to specify homepage toc. Support customized contribute repository and branch for \"Improve this Doc\" button. ( https://github.com/dotnet/docfx/issues/482 ) Improve message for docfx.exe template command. v2.2.2 Fix bug in .manifest file. v2.2.1 Fix bug when metadata incremental check. Move post process out of DocumentBuilder. v2.2 Support multi-version site. ( https://github.com/dotnet/docfx/issues/396 ) Support loop reference for Swagger Rest API. ( https://github.com/dotnet/docfx/issues/223 ) Support plug-in for post processor. Support href for see/seealso tags. Improve API reference documentation of namespace and enum. Update prerequisite to build docfx. Update manifest schema. Add chocolatey support in CI script. Provide with options in build.cmd. Bug fixes: syntax for static class is incorrect. improve warning message about global namespace class. ( https://github.com/dotnet/docfx/issues/417 ) fix normalizexml bug for empty <code></code> in tripleslashcomment. v2.1 Support for xref zip file in relative path. Support anchor in toc file. Support plug-in for validating markdown input metadata. Add output file md5 hashes. Breaking Url Rename generic type file name in metadata step E.g. System.Func<T> will generate System.Func-1.yml instead of System.Func`1.yml , and after build the url will be System.Func-1.html instead of System.Func%601.html . To keep old behavior, please add following option in metadata part in docfx.json: \"useCompatibilityFileName\": true Display extension methods in API reference documentation Provide with option _displayLangs in docfx.json to choose which language version you want to show. Support more Swagger syntax: Support allOf . ( https://github.com/dotnet/docfx/issues/360 ) Support $ref with [ and ] in json pointer. ( https://github.com/dotnet/docfx/issues/359 ) Support parameters applicable for all the operations under path . ( https://github.com/dotnet/docfx/issues/358 ) v2.0.2 Support localization tokens in DFM. v2.0.1 Fix bug that file links can't be resolved in overwrite file v2.0 Breaking Change Add line info for markdown parser. Allow Markdown reference at the end of overwrite file. Provide more information for API reference documentation display inherited members display overridden members display implemented interface separate category for Explicit Interface Implementation Rest api - Enable Tag in Swagger file to organize the API s. v1.9 Breaking Change Refactor template system: The input data model now contains all the properties including system generated metadata starting with underscore _ and globally shared variables stored in __global . You can use docfx build --exportRawModel to view the data model. Preprocessor 's transform function signature changes to: exports.transform = function (model){ // transform the model return model; } Provide a new embedded template statictoc with TOC generated in build time. Webpages generated by this template is PURE static and you can simply open the generated webpage file to take a preview, no local server is needed. Allow switch markdown engine. Allow export metadata to manifest file. Improve exclude logic to help avoid PathTooLongException . ( https://github.com/dotnet/docfx/issues/156 ) Provide with a config file named search-stopwords.json to customise full-text search stop-words. ( https://github.com/dotnet/docfx/issues/279 ) Bug fixes: Fix bug when cref contains loop. ( https://github.com/dotnet/docfx/issues/289 ) Make sure id is unique for each HTML in markdown transforming. ( https://github.com/dotnet/docfx/issues/224 ) Fix index range bugs in YamlHeaderParser . ( https://github.com/dotnet/docfx/issues/265 ) v1.8.4 Fix bug when outputFolder, basedirectory and destination are all not set fix <a> tag when href has invalid value with anchor v1.8.3 Fix bug for [!include()[]] when multiple articles in different subfolder including one file that v1.8.2 not resolved v1.8.2 Fix bug for [!include()[]] when multiple articles in different subfolder including one file v1.8.1 Fix bug when serialize attribute argument for type array. ( https://github.com/dotnet/docfx/issues/280 ) Fix bug when include file link to an anchor. Don't modify link when target file not existed. v1.8 Support multiple regions selection, code lines highlight and dedent length setting in Code Snippet . ( https://github.com/dotnet/docfx/issues/189 ) Support more tags in triple-slash-comments, e.g. lang , list , code , paramref and typeparamref . Add Example section to default template. Bug fixes: Fix bug when parsing triple-slash-comments. ( https://github.com/dotnet/docfx/issues/221 ) Fix syntax generation for VB module. ( https://github.com/dotnet/docfx/issues/260 ) v1.7 Behavior change For articles not in TOC, it's TOC file is the nearest TOC File in its output folder. Previously we only search the TOC File under the same input folder of the Not-In-Toc article. Provide more information for API reference documentation Type of events ( https://github.com/dotnet/docfx/issues/217 ) Parameters/returns for delegates ( https://github.com/dotnet/docfx/issues/218 ) Type parameter description ( https://github.com/dotnet/docfx/issues/204 ) Cross-reference is now supporting anchor # ( https://github.com/dotnet/docfx/issues/190 ) C# Code snippet now supports referencing source code using a region #engion ( https://github.com/dotnet/docfx/issues/160 ) Support TOC reference . With this syntax, we can combine multiple TOC files into a single TOC. ( https://github.com/dotnet/docfx/issues/161 ) Improve user experience when using docfx.msbuild in VS IDE Code refactor: We improved DocFX project structure in this release. Microsoft.DocAsCode.EntityModel namespace is no longer in use. Assemblies are separated into Microsoft.DocAsCode.Build , Microsoft.DocAsCode.DataContracts , and Microsoft.DocAsCode.Metadata namespace. All assemblies can be separately referenced through NuGet. In this way, it is much convenient for plugin writers to reference existing data models and utilities. v1.6 Add attribute in c# and vb syntax. Support full text search, with pure client side implementation: The feature is disabled by default. You can enable it by adding \"_enableSearch\": true to the globalMetadata property of docfx.json . The search engine is powered by lunr.js v1.5 Add 3 options to build subcommand: --rawModelOutputFolder : to specify the output folder for raw model if --exportRawModel . If the value is not set, raw model will be in the same folder as the output documenation. --viewModelOutputFolder : to specify the output folder for view model if --exportViewModel . If the value is not set, view model will be in the same folder as the output documenation. --dryRun : if this option is set, docfx will go through all the build processes for all the documents, however, no documentation will generated. Improve markdown: Allow paired parentheses in link target, e.g. [text](paired(parentheses(are)supported)now \"title\") . Improve performance for document build. Breaking changes: modify interface @Microsoft.DocAsCode.Plugins.IDocumentBuildStep. v1.4.2 Fix bug for encoded link file. Fix bug for directory not found. v1.4.1 Remove newFileRepository from output metadata v1.4 Cross-reference related: Make @uid rule more strict: if @ is not followed by ' or \" , it must be followed by word character ( [a-zA-Z] ) Introduce new syntax for cross-reference: similar to autolink: <xref:uid> similar to link: [title](xref:uid) or [title](@uid) support uid in toc.yml : - uid: getting-started - uid: manual support cross reference in toc.md # <xref:getting-started> # [Override title](@getting-started) Update yaml serializion: Add @Microsoft.DocAsCode.YamlSerialization.ExtensibleMemberAttribute Improve docfx init , now with docfx init , a docfx_project seed project will will generated. Several improvements for default template: Provide properties to customize layout: _disableNavbar , _disableBreadcrumb , _disableToc , _disableAffix , _disableContribution , _disableFooter Include empty main.css and main.js to head.tmpl.partial partial template so that there is no need to customize head.tmpl.partial when you want to customize website style. v1.3.8 Fix no link and ref link cannot work issue in table v1.3.7 Fix no link and ref link cannot work issue in markdownlite. Fix link issue (allow space in link) in markdownlite. Fix para for list in markdownlite. Fix tokenize bug in dfm. Add markdown token validator in dfm. v1.3.6 Fix cross domain issue: timeout exception throws when document build takes longer than 15 minutes Fix docfx IOException when calling docfx -l report.txt v1.3.5 FIX Github pages compatibility issue( Github pages now disallow iframe , however the default template of docfx uses iframe to load side toc): Update default template to use AJAX to load side toc, the original one is renamed to iframe.html . So now we have 2 embedded template, one is default and another is iframe.html . v1.3 docfx improvements Add subcommand docfx template . You can now docfx template list and docfx template export -A to list and export all the embeded templates! Add subcommand docfx merge . You can use this subcommand to merge platform from multiple APIs with the same uid Add two options to build subcommand, --exportRawModel and --exportViewModel . --exportRawModel exports the data model to apply templates, --exportViewModel exports the view model after running template's pre-process scripts. Add --globalMetadata , and --globalMetadataFile options to build subcommand. These options allow globalMetadata to be loaded from command line in json format or from a JSON file. Add --fileMetadataFile option to build subcommand. This option allows fileMeatdata to be read from an external JSON file. Support plugins. You can create your own template with a plugins folder, inside which, you create your own build steps. Refer to @Microsoft.DocAsCode.EntityModel.Plugins.BaseDocumentBuildStep for a sample plugin implementation. DFM syntax improvements Support note&div syntax Support query format in code snippet [!code-<language>[<name>](<codepath><queryoption><queryoptionvalue> \"<title>\")] Change xref logic: If content after @ is wrapped by ' or \" , it contains any character including white space If content after @ is not wrapped by ' or \" , it ends when: line ends meets whitespaces line ends with . , , , ; , : , ! , ? and ~ meets 2 times or more . , , , ; , : , ! , ? and ~ Code improvements Add @Microsoft.DocAsCode.YamlSerialization This project is based on YamlDotNet . It overrides classes like type converters to improve performance and fix bug existed in YamlDotNet Refactor markdown engine @Microsoft.DocAsCode.MarkdownLite Add @Microsoft.DocAsCode.MarkdownLite.IMarkdownRewritable`1. It provides a way to operate markdown tokens. Other improvements Add a new property _path into _attrs , it stands for the relative path from docfx.json to current file Improve missing xref warning message to include containing files. Add data-uid as attribute to generated html from default template, so that you can now find uid for API much more easily. v1.2 Support Liquid template, templates ending with .liquid are considered as using liquid templating language. Liquid contains include tag to support partials, we follow the ruby partials naming convention to have _<partialName>.liquid as partial template. A custom tag ref , e.g. {% ref file1 %} is introduced to specify the resource files that current template depends on. DFM include syntax is updated to use [!include[<title>](<filepath>)] syntax Disable glob pattern in docfx metadata command line option as it is to some extent confusing, consider using a -g option later to re-enable it. v1.1 Rewrite Glob The syntax of glob is: ** is called globstar, it matches any number of characters, including / , as long as it's the only thing in a path part. If ** is right behind / , it is a shortcut for **/* . * matches any number of characters, but not / ? matches 1 characters, but not / {} allows for a comma-separated list of \"or\" expressions, e.g. {a,b} => a and b ! at the beginning of a pattern will negate the match [...] matches a range of characters, similar to a RegExp range / is considered as path separator, while \\ is considered as escape character Support fileMetadata . You can specify different metadata value using glob pattern Improve overwrite functionality. Now you can overwrite not only summary/remarks, but also descriptions for parameters. You can even add exceptions. Now the latest project.json projects are also supported in DNX version. Simple code snippet is now supported, syntax is [!code-REST-i[title](path \"optionalTitle\")] Url is now encoded in markdown link. v1.0 Add section syntax in DFM Fix several bugs in DFM Update default template: rename css/js file Fix several display issue in default template v0.3 Support Static Website Templates Schema change to docfx.json"
  },
  "index.html": {
    "href": "index.html",
    "title": "Welcome to DocFX website! | DocFX website",
    "keywords": ""
  },
  "install.html": {
    "href": "install.html",
    "title": "Thanks for installing DocFX! | DocFX website",
    "keywords": ""
  },
  "tutorial/docfx.exe_user_manual.html": {
    "href": "tutorial/docfx.exe_user_manual.html",
    "title": "docfx.exe User Manual | DocFX website",
    "keywords": "Doc-as-code: docfx.exe User Manual 0. Introduction docfx.exe is used to generate documentation for programs. It has the ability to: Extract language metadata for programing languages as defined in Metadata Format Specification . Currently language VB and CSharp are supported. The language metadata will be saved with YAML format as described in YAML 1.2 . Look for available conceptual files as provided and link it with existing programs with syntax described in Section 3. Work with Metadata in Markdown . Supported conceptual files are plain text files, html files, and markdown files. Generate documentation to a. Visualize language metadata, with extra content provided by linked conceptual files using syntax described in Section 3. Work with Metadata in Markdown . b. Organize and render available conceptual files. It can be easily cross-referenced with language metadata pages. We support Docfx Flavored Markdown(DFM) for writing conceptual files. DFM is 100% compatible with Github Flavored Markdown(GFM) and add several new features including file inclusion , cross reference , and yaml header . For detailed description about DFM, please refer to DFM . Currently generating documentations to a client only website is supported. The generated website can be easily published to whatever platform such as Github Pages and Azure Website with no extra effort. Offline documentations such as pdf are planned to be supported in the future. 1. Syntax docfx <command> [<args>] 2. Commands 2.0 Init command docfx init docfx init helps generate an docfx.json file. 2.1 Help command docfx help docfx help -a list available subcommands. docfx help <command> to read about a specific subcommand 2.2 Extract language metadata command docfx metadata Syntax docfx metadata [<projects>] Layout |-- <metadata folder> |-- api | |-- <namespace>.yml | |-- <class>.yml |-- toc.yml |-- index.yml 2.2.1 Optional <projects> argument <projects> specifies the projects to have metadata extracted. There are several approaches to extract language metadata. From a supported project file or project file list Supported project file extensions include .csproj , .vbproj , .sln , and project.json . Note project.json ( DNX project file) is only supported in DNX version of DocFX . Please refer to Getting Started for how to use DocFX in DNX . Files can be combined using , as separator, e.g. docfx metadata a.csproj,b.sln . From a supported source code file or source code file list Supported source code file extensions include .cs and .vb . Files can be combined using , as separator and search pattern . From docfx.json file, as described in Section3 . If the argument is not specified, docfx.exe will try reading docfx.json under current directory. The default output folder is _site/ folder if it is not specified in docfx.json under current directory. 2.3 Generate documentation command docfx build Syntax docfx build [-o:<output_path>] [-t:<template folder>] docfx build generates documentation for current folder. If toc.yml or toc.md is found in current folder, it will be rendered as the top level TABLE-OF-CONTENT. As in website, it will be rendered as the top navigation bar. NOTE that homepage is not supported in toc.md . And if href is referencing to a folder , it must end with / . toc.yml syntax toc.yml is an array of items. Each item can have following properties: Property Description name Requried . The title of the navigation page. href Required . Can be a folder or a file UNDER current folder. Folder must be end with / . If is a folder, TOC.md inside the folder will be rendered as second level TABLE-OF-CONTENT. As in website, it will be rendered as sidebar. homepage The default content shown when no article is selected. TOC.yml Sample - name: Home href: articles/Home.md - name: Roslyn Wiki href: roslyn_wiki/ - name: Roslyn API href: api_roslyn/ homepage: homepages/roslyn_language_features.md TOC.md Sample ## [Home](articles/Home.md) ## [Roslyn Wiki](roslyn_wiki/) ## [Roslyn API](api_roslyn/) 2.3.1 Optional <output_path> argument The default output folder is _site/ folder 2.3.2 Optional <template folder> argument If specified, use the template from template folder Template Folder Structure |-- <template folder> |-- index.html |-- styles | |-- docascode.css | |-- docascode.js |-- template | |-- toc.html | |-- navbar.html | |-- yamlContent.html |-- favicon.ico |-- logo.ico 3. docfx.json Format Top level docfx.json structure is key-value pair. key is the name of the subcommand, current supported subcommands are metadata and build . 3.1 Properties for metadata Metadata section defines an array of source projects and their output folder. Each item has src and dest property. src defines the source projects to have metadata generated, which is in File Mapping Format . Detailed syntax is described in 4. Supported name-files File Mapping Format below. dest defines the output folder of the generated metadata files. Sample { \"metadata\": [ { \"src\": [ { \"files\": [\"**/*.csproj\"], \"exclude\": [ \"**/bin/**\", \"**/obj/**\" ], \"src\": \"../src\" } ], \"dest\": \"obj/docfx/api/dotnet\" }, { \"src\": [ { \"files\": [\"**/*.js\"], \"src\": \"../src\" } ], \"dest\": \"obj/docfx/api/js\" } ] } 3.2 Properties for build Key Description content Contains all the files to generate documentation, including metadata yml files and conceptual md files. name-files file mapping with several ways to define it, as to be described in Section4 . The files contains all the project files to have API generated. resource Contains all the resource files that conceptual and metadata files dependent on, e.g. image files. name-files file mapping with several ways to define it, as to be described in Section4 . overwrite Contains all the conceputal files which contains yaml header with uid and is intended to override the existing metadata yml files. name-files file mapping with several ways to define it, as to be described in Section4 . globalMetadata Contains metadata that will be applied to every file, in key-value pair format. For example, you can define \"_appTitle\": \"This is the title\" in this section, and when applying template default , it will be part of the page title as defined in the template. fileMetadata Contains metadata that will be applied to specific files. name-files file mapping with several ways to define it, as to be described in Section4 . globalMetadataFile Obsoleted , Specify a JSON file path containing globalMetadata settings, as similar to {\"globalMetadata\":{\"key\":\"value\"}} . globalMetadataFiles Specify a list of JSON file path containing globalMetadata settings, as similar to {\"key\":\"value\"} . Please read Section3.2.3 for detail. fileMetadataFile Obsoleted , Specify a JSON file path containing fileMetadata settings, as similar to {\"fileMetadata\":{\"key\":\"value\"}} . fileMetadataFiles Specify a list of JSON file path containing fileMetadata settings, as similar to {\"key\":\"value\"} . Please read Section3.2.3 for detail. template The templates applied to each file in the documentation. It can be a string or an array. The latter ones will override the former ones if the name of the file inside the template collides. If ommited, embedded default template will be used. theme The themes applied to the documentation. Theme is used to customize the styles generated by template . It can be a string or an array. The latter ones will override the former ones if the name of the file inside the template collides. If ommited, no theme will be applied, the default theme inside the template will be used. externalReferences Obsoleted , Contains rpk files that define the external references. name-files file mapping with several ways to define it, as to be described in Section4 . xref Specifies the urls of xrefmap used by content files. Currently, it supports following scheme: http, https, ftp, file, embedded. exportRawModel If set to true, data model to run template script will be extracted in .raw.json extension. rawModelOutputFolder Specify the output folder for the raw model. If not set, the raw model will be generated to the same folder as the output documentation. exportViewModel If set to true, data model to apply template will be extracted in .view.json extension. viewModelOutputFolder Specify the output folder for the view model. If not set, the view model will be generated to the same folder as the output documentation. dryRun If set to true, template will not be actually applied to the documents. This option is always used with --exportRawModel or --exportViewModel , so that only raw model files or view model files are generated. maxParallelism Set the max parallelism, 0 (default) is same as the count of CPU cores. markdownEngineName Set the name of markdown engine, default is dfm , and another build-in engine is gfm . markdownEngineProperties Set the parameters for markdown engine, value should be a JSON string. noLangKeyword Disable default lang keyword, it can be downloaded from here . 3.2.1 Template s and Theme s Template s are used to transform YAML files generated by docfx to human-readable page s. A page can be a markdown file, a html file or even a plain text file. Each YAML file will be transformed to ONE page and be exported to the output folder preserving its relative path to src . For example, if page s are in HTML format, a static website will be generated in the output folder. Theme is to provide general styles for all the generated page s. Files inside a theme will be generally COPIED to the output folder. A typical usage is, after YAML files are transformed to HTML pages, well-designed CSS style files in a Theme can then overwrite the default styles defined in template , e.g. main.css . There are two ways to use custom templates and themes. To use a custom template, one way is to specify template path with --template (or -t ) command option, multiple templates must be separated by , with no spaces. The other way is to set key-value mapping in docfx.json : { ... { \"build\" : { ... \"template\": \"custom\", ... } ... } { ... { \"build\" : { ... \"template\": [\"default\", \"X:/template/custom\"], ... } ... } The template path could either be a zip file called <template>.zip or a folder called <template> . To custom theme, one way is to specify theme name with --theme command option, multiple themes must be separated by , with no spaces. The other way is to set key-value mapping in docfx.json as similar to defining template. Also, both .zip file and folder are supported. Please refer to How to Create Custom Templates to create custom templates. Sample { \"build\": { \"content\": [ { \"files\": [\"**/*.yml\"], \"src\": \"obj/docfx\" }, { \"files\": [\"tutorial/**/*.md\", \"spec/**/*.md\", \"spec/**/toc.yml\"] }, { \"files\": [\"toc.yml\"] } ], \"resource\": [ { \"files\": [\"spec/images/**\"] } ], \"overwrite\": \"apispec/*.md\", \"externalReference\": [ ], \"globalMetadata\": { \"_appTitle\": \"DocFX website\" }, \"dest\": \"_site\", \"template\": \"default\" } } 3.2.2 Reserved Metadata After passing values through global metadata or file metadata, DocFX can use these metadata in templates to control the output html. Reserved metadatas: Metadata Name Type Description _appTitle string Will be appended to each output page's head title. _appFooter string The footer text. Will show DocFX's Copyright text if not specified. _enableSearch bool Indicate whether to show the search box on the top of page. _disableNavbar bool Indicate whether to show the navigation bar on the top of page. _disableBreadcrumb bool Indicate whether to show breadcrumb on the top of page. _disableToc bool Indicate whether to show table of contents on the left of page. _disableAffix bool Indicate whether to show the affix bar on the right of page. _disableContribution bool Indicate whether to show the View Source and Improve this Doc buttons. _gitContribute object Customize the Improve this Doc URL button for public contributors. Use repo to specify the contribution repository URL. Use branch to specify the contribution branch. Use path to specify the folder for new overwrite files. If not set, the git URL and branch of the current git repository will be used. _gitUrlPattern string Choose the URL pattern of the generated link for View Source and Improve this Doc . Supports github and vso currently. If not set, DocFX will try speculating the pattern from domain name of the git URL. 3.2.3 Separated metadata files for global metadata and file metadata There're three ways to set metadata for a file in DocFX: using global metadata, it will set metadata for every file. using file metadata, it will set metadata for files that match pattern. using YAML header, it will set metadata for current file. In above ways, the later way will always overwrite the former way if the same key of metadata is set. Here we will show you how to set global metadata and file metadata using separated metadata files. Take global metadata for example, you can set globalMetadataFiles in docfx.json or --globalMetadataFiles in build command line. The usage of fileMetadataFiles is the same as globalMetadataFiles . There're some metadata file examples: globalMetadata file example { \"_appTitle\": \"DocFX website\", \"_enableSearch\": \"true\" } fileMetadata file example { \"priority\": { \"**.md\": 2.5, \"spec/**.md\": 3 }, \"keywords\": { \"obj/docfx/**\": [\"API\", \"Reference\"], \"spec/**.md\": [\"Spec\", \"Conceptual\"] } } There're some examples about how to use separated metadata files. use globalMetadataFiles in docfx.json ... \"globalMetadataFiles\": [\"global1.json\", \"global2.json\"], ... use --globalMetadataFiles in build command line docfx build --globalMetadataFiles global1.json,global2.json use fileMetadataFiles in docfx.json ... \"fileMetadataFiles\": [\"file1.json\", \"file2.json\"], ... use --fileMetadataFiles in build command line docfx build --fileMetadataFiles file1.json,file2.json Note that, metadata set in command line will merge with metadata set in docfx.json . If same key for global metadata was set, the order to be overwritten would be(the later one will overwrite the former one): global metadata from docfx config file global metadata from global metadata files global metadata from command line If same file pattern for file metadata was set, the order to be overwritten would be(the later one will overwrite the former one): file metadata from docfx config file file metadata from file metadata files Given multiple metadata files, the behavior would be undetermined , if same key is set in these files. 4. Supported File Mapping Format There are several ways to define file mapping. 4.1 Array Format This form supports multiple file mappings, and also allows additional properties per mapping. Supported properties: Property Name Description files REQUIRED . The file or file array, glob pattern is supported. name Obsoleted , please use dest . exclude The files to be excluded, glob pattern is supported. cwd Obsoleted , please use src . src Specifies the source directory. If omitted, the directory of the config file will be used. Use this option when you want to refer to files in relative folders while want to keep folder structure. e.g. set src to .. . dest The folder name for the generated files. version Version name for the current file mapping. If not set, treat the current file-mapping item as in default version. Mappings with the same version name will be built together. Cross reference doesn't support cross different versions. caseSensitive TOBEIMPLEMENTED . Default value is false . If set to true , the glob pattern is case sensitive. e.g. *.txt will not match 1.TXT . For OS Windows, file path is case insensitive while for Linux/Unix, file path is case sensitive. This option offers user the flexibility to determine how to search files. supportBackslash TOBEIMPLEMENTED . Default value is true . If set to true , \\ will be considered as file path separator. Otherwise, \\ will be considered as normal character if escape is set to true and as escape character if escape is set to false . If escape is set to true , \\\\ should be used to represent file path separator. escape TOBEIMPLEMENTED . Default value is false . If set to true , \\ character is used as escape character, e.g. \\{\\}.txt will match {}.txt . \"key\": [ {\"files\": [\"file1\", \"file2\"], \"dest\": \"dest1\"}, {\"files\": \"file3\", \"dest\": \"dest2\"}, {\"files\": [\"file4\", \"file5\"], \"exclude\": [\"file5\"], \"src\": \"folder1\"}, {\"files\": \"Example.yml\", \"src\": \"v1.0\", \"dest\":\"v1.0/api\", \"version\": \"v1.0\"}, {\"files\": \"Example.yml\", \"src\": \"v2.0\", \"dest\":\"v2.0/api\", \"version\": \"v2.0\"} ] 4.2 Compact Format \"key\": [\"file1\", \"file2\"] 4.3 Glob Pattern DocFX uses Glob to support glob pattern in file path. It offers several options to determine how to parse the Glob pattern: caseSensitive : Default value is false . If set to true , the glob pattern is case sensitive. e.g. *.txt will not match 1.TXT . For OS Windows, file path is case insensitive while for Linux/Unix, file path is case sensitive. This option offers user the flexibility to determine how to search files. supportBackslash : Default value is true . If set to true , \\ will be considered as file path separator. Otherwise, \\ will be considered as normal character if escape is set to true and as escape character if escape is set to false . If escape is set to true , \\\\ should be used to represent file path separator. escape : Default value is false . If set to true , \\ character is used as escape character, e.g. \\{\\}.txt will match {}.txt . In general, the glob pattern contains the following rules: * matches any number of characters, but not / ? matches a single character, but not / ** matches any number of characters, including / , as long as it's the only thing in a path part {} allows for a comma-separated list of OR expressions SAMPLES 5. Q & A Do we support files outside current project folder(the folder when docfx.json exists)? A: YES. DO specify src and files outside of current folder will be copied to output folder keeping the same relative path to src . Do we support output folder outside current project folder(the folder when docfx.json exists)? A: YES. Do we support referencing files outside of current project folder(the folder when docfx.json exists)? A: NO."
  },
  "tutorial/docfx_getting_started.html": {
    "href": "tutorial/docfx_getting_started.html",
    "title": "Getting Started with DocFX | DocFX website",
    "keywords": "Getting Started with DocFX 1. What is DocFX DocFX is an API documentation generator for .NET, and currently it supports C# and VB. It generates API reference documentation from triple-slash comments in your source code. It also allows you to use Markdown files to create additional topics such as tutorials and how-tos, and to customize the generated reference documentation. DocFX builds a static HTML website from your source code and Markdown files, which can be easily hosted on any web servers (for example, github.io ). Also, DocFX provides you the flexibility to customize the layout and style of your website through templates. If you are interested in creating your own website with your own styles, you can follow how to create custom template to create custom templates. DocFX also has the following cool features: Integration with your source code. You can click \"View Source\" on an API to navigate to the source code in GitHub (your source code must be pushed to GitHub). Cross-platform support. We have both exe version that runs under Windows and a DNX version that runs cross platform. Integration with Visual Studio. You can seamlessly use DocFX within Visual Studio. Markdown extensions. We introduced DocFX Flavored Markdown(DFM) to help you write API documentation. DFM is 100% compatible with GitHub Flavored Markdown(GFM) with some useful extensions, like file inclusion , code snippet , cross reference , and yaml header . For detailed description about DFM, please refer to DFM . 2. Use DocFX as a command-line tool Step1. Download and unzip docfx.zip from https://github.com/dotnet/docfx/releases , extract it to a local folder, and add it to PATH so you can run it anywhere. Step2. Create a sample project docfx init -q This command generates a default project named docfx_project . Step3. Build the website docfx docfx_project\\docfx.json --serve Now you can view the generated website on http://localhost:8080 . 3. Use DocFX in Visual Studio As a prerequisite, you need Visual Studio 2015 to use DocFX in IDE. Step1. Open Visual Studio and create a C# project as your documentation project. You can create an empty ASP.NET Web Application since it has a built-in preview feature that can be used to preview the generated website easily. Step2. Right click on the website project, and choose Manage NuGet Packages... to open the NuGet Package Manager. Search and install docfx.msbuild package. Step3. Create a .cs class in the website project, make sure the class is public , for example: namespace WebApplication1 { public class Class1 { } } Step4. Right click on the website project, and click View -> View in Browser , navigate to /_site sub URL to view your website! 4. Use DocFX under DNX As a prerequisite, you need to install DNVM and DNX . Step1. SET DNX_FEED=https://www.myget.org/F/aspnetrelease/api/v2/ as we depend upon the release version of ASP.NET 1.0.0-rc1. Step2. dnvm upgrade to get the latest dnvm. Step3. Add feed https://www.myget.org/F/aspnetrelease/api/v2/ to NuGet.config. For Windows, the NuGet config file is %AppData%\\NuGet\\NuGet.config . For Linux/OSX, the NuGet config file is ~/.config/NuGet/NuGet.config . Sample NuGet.config <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <packageSources> <add key=\"myget.release\" value=\"https://www.myget.org/F/aspnetrelease/api/v2/\" /> <add key=\"nuget.org\" value=\"https://www.nuget.org/api/v2/\" /> </packageSources> <disabledPackageSources /> <activePackageSource> <add key=\"nuget.org\" value=\"https://www.nuget.org/api/v2/\" /> </activePackageSource> </configuration> Step4. dnu commands install docfx to install DocFX as a command. Step5. docfx init -q to generate a sample project. Step6. docfx docfx_project\\docfx.json --serve to build your project and preview your site at http://localhost:8080 . Please refer to DocFX User Manual for detailed description of docfx.json . 5. Build from source code Build without DNX There're two options: Run build nondnx under DocFX code repo Open NonDNX.sln under DocFX code repo in Visual Studio and build it. Build with DNX As a prerequisite, you need: Microsoft Build Tools 2015 DNVM Node.js Step1. git clone https://github.com/dotnet/docfx.git to get the latest code. Step2. dnvm install 1.0.0-rc1-final Step3. Run build.cmd under root folder. Step4. Add artifacts folder to nuget source by in IDE: Tools > NuGet Package Manager > Package Manager Settings > Package Sources Step5. Follow steps in #2, #3, #4 to use DocFX in command-line, IDE or DNX. 6. A seed project to play with DocFX Here is a seed project https://github.com/docascode/docfx-seed . It contains A basic C# project under src . Several conceptual files under articles . An overwrite file to add extra content to API under specs . toc.yml under root folder. It renders as the navbar of the website. docfx.json under root folder. It is the configuration file that docfx depends upon. Tip: It is a good practice to separate files with different type into different folders. 7. Q&A Q: How do I quickly reference APIs from other APIs or conceptual files? A: Use @uid syntax. Q: What is uid and where do I find uid ? A: Refer to Cross Reference section in DFM . Q: How do I quickly find uid in the website? A: In the generated website, hit F12 to view source, and look at the title of an API. You can find uid in data-uid attribute."
  },
  "tutorial/howto_add_a_customized_post_processor.html": {
    "href": "tutorial/howto_add_a_customized_post_processor.html",
    "title": "How-to: Add a customized post-processor | DocFX website",
    "keywords": "How-to: Add a customized post-processor We provide the ability to process output files by adding a customized post-processor. In DocFX, the index file for full-text-search is generated by one post-processor named ExtractSearchIndex . In this topic, we will show how to add a customized post-processor. Step0: Preparation Create a new C# class library project in Visual Studio . Add nuget packages: System.Collections.Immutable with version 1.1.37 Microsoft.Composition with version 1.0.27 Add Microsoft.DocAsCode.Plugins If you are building DocFX from source code, add this reference to the project, otherwise add the nuget package Microsoft.DocAsCode.Plugins with the same version as DocFX. Step1: Create a new class (MyProcessor.cs) with the following code: [Export(nameof(MyProcessor), typeof(IPostProcessor))] public class MyProcessor : IPostProcessor { // TODO: implements IPostProcessor } Step2: Update global metadata public ImmutableDictionary<string, object> PrepareMetadata(ImmutableDictionary<string, object> metadata) { // TODO: add/remove/update property from global metadata return metadata; } In this method, we can update the global metadata before building all the files declared in docfx.json . Otherwise, you can just return the metadata from parameters if you don't need to change global metadata. Using ExtractSearchIndex for example, we add \"_enableSearch\": true in global metadata. The default template would then know it should load a search box in the navbar. Step3: Process all the files generated by DocFX public Manifest Process(Manifest manifest, string outputFolder) { // TODO: add/remove/update all the files included in manifest return manifest; } Input for the method manifest contains a list of all files to process, and outputFolder specifies the output folder where our static website will be placed. We can implement customized operations here to process all files generated by DocFX. Using ExtractSearchIndex for example again, we traverse all HTML files, extract key words from these HTML files and save a file named index.json under the outputFolder . Finally we return the manifest which is not modified. Step4: Build your project and copy the output dll files to: Global: the folder with name Plugins under DocFX.exe Non-global: the folder with name Plugins under a template folder, then run DocFX build command with parameter -t {template} . Hint : DocFX can merge templates, so we can specify multiple template folders as DocFX build -t {templateForRender},{templateForPlugins} . Each of the template folders should have a subfolder named Plugins with exported assemblies. Step5: Add your post processor in docfx.json In this step, we need to enable the processor by adding its name in docfx.json . Here is an example: { \"build\": { ... \"postProcessors\": [\"OutputPDF\", \"BeautifyHTML\", \"OutputPDF\"] } } As you can see, the postProcessors is an array, which means it could have multiple processors. It needs to be pointed out that the order of postProcessors written in docfx.json is also the order to process output files. In the above example, DocFX will run OutputPDF first, then BeautifyHTML , and then OutputPDF again. If you want to enable the post processors without changing docfx.json , you can use the build command option like docfx build --postProcessors=OutputPDF,BeautifyHTML,OutputPDF . One more thing need to be noted: the build command option postProcessors would override the corresponding configuration in docfx.json ."
  },
  "tutorial/howto_build_your_own_type_of_documentation_with_custom_plug-in.html": {
    "href": "tutorial/howto_build_your_own_type_of_documentation_with_custom_plug-in.html",
    "title": "How-to: Build your own type of documentation with a custom plug-in | DocFX website",
    "keywords": "How-to: Build your own type of documentation with a custom plug-in In this topic we will create a plug-in to convert some simple rich text format files to html documents. Goal and limitation In scope: Our input will be a set of rtf files with .rtf as the file extension name. The rtf files will be built as html document. Out of scope: Picture or other object in rtf files. Hyperlink in rtf files. (in the advanced tutorial , we will describe how to support hyperlinks in a custom plugin.) Metadata and title. Preparation Create a new C# class library project in Visual Studio . Add nuget packages: System.Collections.Immutable with version 1.1.37 Microsoft.Composition with version 1.0.27 Add Microsoft.DocAsCode.Plugins If building DocFX from source code then add a reference to the project, otherwise add the nuget package Microsoft.DocAsCode.Plugins with the same version as DocFX. Add framework assembly references: PresentationCore , PresentationFramework , WindowsBase Add a project for converting rtf to html: Clone project MarkupConverter , and reference it. Copy the code file StaTaskScheduler.cs from ParExtSamples Create a document processor Responsibility of the document processor Declare which file can be handled. Load from the file to the object model. Provide build steps. Report document type, file links and xref links in document. Update references. Create our RtfDocumentProcessor Create a new class (RtfDocumentProcessor.cs) with the following code: [Export(typeof(IDocumentProcessor))] public class RtfDocumentProcessor : IDocumentProcessor { // todo : implements IDocumentProcessor. } Declare that we can handle the .rtf file: public ProcessingPriority GetProcessingPriority(FileAndType file) { if (file.Type == DocumentType.Article && \".rtf\".Equals(Path.GetExtension(file.File), StringComparison.OrdinalIgnoreCase)) { return ProcessingPriority.Normal; } return ProcessingPriority.NotSupported; } Here we declare this processor can handle any .rtf file in the article category with normal priority. When two or more processors compete for the same file, DocFX will give it to the higher priority one. Unexpected : two or more processor declare for the same file with same priority. Load our rtf file by reading all text: public FileModel Load(FileAndType file, ImmutableDictionary<string, object> metadata) { var content = new Dictionary<string, object> { [\"conceptual\"] = File.ReadAllText(Path.Combine(file.BaseDir, file.File)), [\"type\"] = \"Conceptual\", [\"path\"] = file.File, }; return new FileModel(file, content); } We use Dictionary<string, object> as the data model, similar to how ConceptualDocumentProcessor stores the content of markdown files. Implement Save method as follows: public SaveResult Save(FileModel model) { return new SaveResult { DocumentType = \"Conceptual\", ModelFile = model.File, LinkToFiles = linkToFiles.ToImmutableArray(), }; } BuildSteps property can provide several build steps for the model. We suggest implementing this in the following manner: [ImportMany(nameof(RtfDocumentProcessor))] public IEnumerable<IDocumentBuildStep> BuildSteps { get; set; } Name property is used to display in the log, so give any constant string you like. e.g.: public string Name => nameof(RtfDocumentProcessor); Since we don't support hyperlink, keep the UpdateHref method empty. public void UpdateHref(FileModel model, IDocumentBuildContext context) { } View the final RtfDocumentProcessor.cs Create a document build step Responsibility of the build step Reconstruct documents via the Prebuild method, e.g.: remove some document according to a certain rule. Transform document content via Build method, e.g.: transform rtf content to html content. Transform more content required by all document processed via the PostBuild method, e.g.: extract the link text from the title of another document. About build order: For all documents in one processor always Prebuild -> Build -> Postbuild . For all documents in one processor always invoke Prebuild by BuildOrder . For each document in one processor always invoke Build by BuildOrder . For all documents in one processor always invoke Postbuild by BuildOrder . e.g.: Document processor X has two steps: A (with BuildOrder=1), B (with BuildOrder=2). When X is handling documents [D1, D2, D3], the invoke order is as follows: A.Prebuild([D1, D2, D3]) returns [D1, D2, D3] B.Prebuild([D1, D2, D3]) returns [D1, D2, D3] Parallel( A.Build(D1) -> B.Build(D1), A.Build(D2) -> B.Build(D2), A.Build(D3) -> B.Build(D3) ) A.Postbuild([D1, D2, D3]) B.Postbuild([D1, D2, D3]) Create our RtfBuildStep: Create a new class (RtfBuildStep.cs), and declare it is a build step for RtfDocumentProcessor : [Export(nameof(RtfDocumentProcessor), typeof(IDocumentBuildStep))] public class RtfBuildStep : IDocumentBuildStep { // todo : implements IDocumentBuildStep. } In the Build method, convert rtf to html: private readonly TaskFactory _taskFactory = new TaskFactory(new StaTaskScheduler(1)); public void Build(FileModel model, IHostService host) { string content = (string)((Dictionary<string, object>)model.Content)[\"conceptual\"]; content = _taskFactory.StartNew(() => RtfToHtmlConverter.ConvertRtfToHtml(content)).Result; ((Dictionary<string, object>)model.Content)[\"conceptual\"] = content; } Implement other methods: public int BuildOrder => 0; public string Name => nameof(RtfBuildStep); public void Postbuild(ImmutableList<FileModel> models, IHostService host) { } public IEnumerable<FileModel> Prebuild(ImmutableList<FileModel> models, IHostService host) { return models; } View the final RtfBuildStep.cs Enable plug-in Build our project. Copy the output dll files to: Global: the folder with name Plugins under DocFX.exe Non-global: the folder with name Plugins under a template folder. Then run DocFX build command with parameter -t {template} . Hint : DocFX can merge templates so create a template that only contains the Plugins folder, then run the command DocFX build with parameter -t {templateForRender},{templateForPlugins} . Build document Run command DocFX init and set the source article with **.rtf . Run command DocFX build ."
  },
  "tutorial/howto_create_custom_template.html": {
    "href": "tutorial/howto_create_custom_template.html",
    "title": "How-to: Create A Custom Template | DocFX website",
    "keywords": "How-to: Create A Custom Template Templates are organized as a zip package or a folder. The file path (without the .zip extension) of the zip package or the path of the folder is considered to be the template name. Quickstart Let's create a template to transform Markdown files into a simple html file. Step 1. Create a template folder Create a folder for the template, for example, c:/docfx_howto/simple_template . Step 2. Add Renderer file Create a file conceptual.html.primary.tmpl under the template folder with the following content: {{{conceptual}}} Now a simple custom template is created. You may notice that DocFX reports a warning message saying that: Warning: [Build Document.Apply Templates]There is no template processing document type(s): Toc . It is because our custom template only specifies how to handle document with type conceptual . To test the output of the template, create a simple documentation project following Walkthrough Part I or download the zipped documentation project directly. In the documentation project, run docfx build docfx.json -t c:/docfx_howto/simple_template --serve . The -t command option specifies the template name(s) used by the current build. Open http://localhost:8080 and you can see a simple web page as follows: Add Preprocessor file Step 3. Add Preprocessor file Sometimes the input data model is not exactly what Renderer wants, you may want to add some properties to the data model, or modify the data model a little bit before applying the Renderer file. This can be done by creating a Preprocessor file. Create a file conceptual.html.primary.js under the template folder with the following content: exports.transform = function (model) { model._extra_property = \"Hello world\"; return model; } Update the file conceptual.html.primary.tmpl with the following content: <h1>{{_extra_property}}</h1> {{{conceptual}}} In the documentation project, run docfx build docfx.json -t c:/docfx_howto/simple_template --serve . Open http://localhost:8080 and you can see _extra_property is added to the web page. Merge template with default template DocFX contains some embedded template resources that you can refer to directly. You can use docfx template list to list available templates provided by DocFX. Take default template as an example. Run docfx template export default . It exports what's inside default template into the folder _exported_templates . You can see that there are sets of Preprocessor and Renderer files to deal with different types of documents. DocFX supports specifying multiple templates for a documentation project. That allows you to leverage the default template for handling other types of documents, together with your custom template. When dealing with multiple templates, DocFX merges the files inside these templates. The principle for merging is: if a file name collides then the file in the latter template overwrites the one in the former template. For example, you can merge default template and your custom template by calling docfx build docfx.json -t default, c:/docfx_howto/simple_template . Multiple templates are split by a comma , in the command line. Or you can define it in docfx.json by: \"build\": { \"template\": [ \"default\", \"c:/docfx_howto/simple_template\" ] } In the documentation project, run docfx build docfx.json -t default,c:/docfx_howto/simple_template --serve . Now the warning message There is no template processing document type(s): Toc disappears because the default template contains Renderer to handle TOC files. Open http://localhost:8080/toc.html and you can see a toc web page. Tip: Run docfx template export default to view what's inside the default template. NOTE: It is possible that DocFX updates its embedded templates when a new version is released. So please make sure to re-export the template if you overwrite or are dependent on it in your custom template."
  },
  "tutorial/howto_filter_out_unwanted_apis_attributes.html": {
    "href": "tutorial/howto_filter_out_unwanted_apis_attributes.html",
    "title": "How-to: Filter Out Unwanted APIs or Attributes | DocFX website",
    "keywords": "How-to: Filter Out Unwanted APIs or Attributes A filter configuration file is in YAML format. You may filter out unwanted APIs or attributes by providing a filter configuration file and specifying its path. Specifying the filter configuration file path The path of the configuration file is specified in the following two ways. Option 1 could overwrite option 2. docfx.exe metadata command argument. docfx.exe metadata -filter <path relative to baseDir or absolutepath> docfx.json metadata section filter property. Sample { \"metadata\": [ { \"src\": [ { \"files\": [ \"src/**.csproj\" ], \"exclude\": [ \"**/bin/**\", \"**/obj/**\" ] } ], \"dest\": \"obj/api\", \"filter\": \"filterConfig.yml\" } ] } DocFX has a default filter configuration . If the user doesn't specify the filter configuration file path, default filter configuration would be used. Otherwise, user provided filter configuration would merge with the default one. If there is a conflict, user specified would overwrite the default one. The format of the filter configuration file 1. API Filter Rules To filter out APIs, you could specify apiRules with a list of exclude or include rules. Note The rules would be executed sequentially and the matching process would stop once one rule is matched. Namely, you need to put the most detailed rule in the top. If no rule is matched the API would be included by default. 1) exclude or include APIs by matching their uid with the Regex uidRegex . The sample below excludes all APIs whose uids start with 'Microsoft.DevDiv' except those that start with 'Microsoft.DevDiv.SpecialCase'. - include: uidRegex: ^Microsoft\\.DevDiv\\.SpecialCase - exclude: uidRegex: ^Microsoft\\.DevDiv 2) exclude or include APIs by matching its type , this is often combined with uidRegex . Supported type : Namespace Type Class Struct Enum Interface Delegate Member Event Field Method Property Note Type could be Class , Struct , Enum , Interface , or Delegate . Member could be Event , Field , Method , or Property . Namespace is flattened. Namely, excluding namespace 'A.B' has nothing to do with namespace 'A.B.C'. If a namespace is excluded, all types/members defined in the namespace would also be excluded. If a type is excluded, all members defined in the type would also be excluded. The below sample would exclude all APIs whose uid starts with 'Microsoft.DevDiv' and type is Type , namely Class , Struct , Enum , Interface , or Delegate . - exclude: uidRegex: ^Microsoft\\.DevDiv type: Type 3) exclude or include APIs by containing matched attributes. You can specify an attribute by its uid , ctorArguments and ctorNamedArguments . Note ctorArguments requires a full match of the attribute's constructor arguments, while ctorNamedArguments supports a partial match. Namely, ctorArguments should contain all the arguments while ctorNamedArguments could contain a subset of the named arguments. The sample below excludes all APIs which have EditorBrowsableAttribute and its constructor argument is EditorBrowsableState.Never. - exclude: hasAttribute: uid: System.ComponentModel.EditorBrowsableAttribute ctorArguments: - System.ComponentModel.EditorBrowsableState.Never The sample below excludes all APIs which have AttributeUsageAttribute and its constructor argument is AttributeTargets.Class and its constructor has named argument [Inherited] = true - exclude: hasAttribute: uid: System.AttributeUsageAttribute ctorArguments: - System.AttributeTargets.Class ctorNamedArguments: Inherited: \"true\" A complete Sample of the filter configuration file for filtering out APIs follows: apiRules: - exclude: uidRegex: ^Microsoft\\.TeamFoundation\\.WorkItemTracking\\.Proxy\\.IRowSetsNative$ - exclude: uidRegex: ^Microsoft\\.TeamFoundation\\.WorkItemTracking\\.Proxy\\.MetadataRowSetsNative$ - exclude: uidRegex: ^Microsoft\\.TeamFoundation\\.WorkItemTracking\\.Proxy\\.RowSet\\.Columns.*$ type: Member - exclude: uidRegex: ^Microsoft\\.TeamFoundation\\.WorkItemTracking\\.Proxy\\.RowSetColumn\\.Name.*$ type: Member - exclude: hasAttribute: uid: System.ComponentModel.EditorBrowsableAttribute ctorArguments: - System.ComponentModel.EditorBrowsableState.Never 2. Attribute Filter Rules To filter out Attributes, you could specify attributeRules with a list of exclude or include rules. The rules are similar to API filter. Please refer to API Filter Rules section. 3. Default Filter Configuration apiRules: - exclude: hasAttribute: uid: System.ComponentModel.EditorBrowsableAttribute ctorArguments: - System.ComponentModel.EditorBrowsableState.Never attributeRules: - exclude: uidRegex: ^System\\.ComponentModel\\.Design$ type: Namespace - exclude: uidRegex: ^System\\.ComponentModel\\.Design\\.Serialization$ type: Namespace - exclude: uidRegex: ^System\\.Xml\\.Serialization$ type: Namespace - exclude: uidRegex: ^System\\.Web\\.Compilation$ type: Namespace - exclude: uidRegex: ^System\\.Runtime\\.Versioning$ type: Namespace - exclude: uidRegex: ^System\\.Runtime\\.ConstrainedExecution$ type: Namespace - exclude: uidRegex: ^System\\.EnterpriseServices$ type: Namespace - exclude: uidRegex: ^System\\.Diagnostics\\.CodeAnalysis$ type: Namespace - include: uidRegex: ^System\\.Diagnostics\\.(ConditionalAttribute|EventLogPermissionAttribute|PerformanceCounterPermissionAttribute)$ type: Type - exclude: uidRegex: '^System\\.Diagnostics\\.[^.]+$' type: Type - include: uidRegex: ^System\\.ComponentModel\\.(BindableAttribute|BrowsableAttribute|ComplexBindingPropertiesAttribute|DataObjectAttribute|DefaultBindingPropertyAttribute|ListBindableAttribute|LookupBindingPropertiesAttribute|SettingsBindableAttribute|TypeConverterAttribute)$ type: Type - exclude: uidRegex: '^System\\.ComponentModel\\.[^.]+$' type: Type - exclude: uidRegex: ^System\\.Reflection\\.DefaultMemberAttribute$ type: Type - exclude: uidRegex: ^System\\.CodeDom\\.Compiler\\.GeneratedCodeAttribute$ type: Type - include: uidRegex: ^System\\.Runtime\\.CompilerServices\\.ExtensionAttribute$ type: Type - exclude: uidRegex: '^System\\.Runtime\\.CompilerServices\\.[^.]+$' type: Type - include: uidRegex: ^System\\.Runtime\\.InteropServices\\.(ComVisibleAttribute|GuidAttribute|ClassInterfaceAttribute|InterfaceTypeAttribute)$ type: Type - exclude: uidRegex: '^System\\.Runtime\\.InteropServices\\.[^.]+$' type: Type - include: uidRegex: ^System\\.Security\\.(SecurityCriticalAttribute|SecurityTreatAsSafeAttribute|AllowPartiallyTrustedCallersAttribute)$ type: Type - exclude: uidRegex: '^System\\.Security\\.[^.]+$' type: Type - include: uidRegex: ^System\\.Web\\.UI\\.(ControlValuePropertyAttribute|PersistenceModeAttribute|ValidationPropertyAttribute|WebResourceAttribute|TemplateContainerAttribute|ThemeableAttribute|TemplateInstanceAttribute)$ type: Type - exclude: uidRegex: '^System\\.Web\\.UI\\.[^.]+$' type: Type - include: uidRegex: ^System\\.Windows\\.Markup\\.(ConstructorArgumentAttribute|DesignerSerializationOptionsAttribute|ValueSerializerAttribute|XmlnsCompatibleWithAttribute|XmlnsDefinitionAttribute|XmlnsPrefixAttribute)$ type: Type - exclude: uidRegex: '^System\\.Windows\\.Markup\\.[^.]+$' type: Type"
  },
  "tutorial/intro_markdown_lite.html": {
    "href": "tutorial/intro_markdown_lite.html",
    "title": "Markdown Lite | DocFX website",
    "keywords": "Markdown Lite Introduction Markdown lite is a simple markdown tool to markup md file. Design goal We write this tool for good extensibility, so our implementation should obey following principles: Extensibility: Support markdown syntax extension. Support validation extension. Correctness: We follow GFM syntax, but when some rules is too hard to implement, just breaking. Performance: Performance is not our major concern. Steps There are three steps when calling markup method : Parse Rewrite or validate Render Step 1: Parse In this step, it will parse markdown text to tokens . The parser is based on rules , which make up the context . For example, heading token is created by heading rule , the heading rule is belonging to block context . Step 2: Rewrite or validate In this step, it will walk through all tokens , we can change it to another, or just validate. For example, we can create a rewriter to change all heading token with depth + 1: MarkdownTokenRewriterFactory.FromLambda<IMarkdownRewriteEngine, MarkdownHeadingBlockToken>( (engine, token) => new MarkdownHeadingBlockToken(token.Rule, token.Context, token.Content, token.Id, token.Depth + 1, token.SourceInfo); Step 3: Render In this step, it renders models to text content (html format by default). To simplify extension, we created an adapter , the adapter invoke methods by following rules: Method name is Render Instance method Return type is @Microsoft.DocAsCode.MarkdownLite.StringBuffer The count of parameters is 3, and types are following: @Microsoft.DocAsCode.MarkdownLite.IMarkdownRenderer or any type implements it. @Microsoft.DocAsCode.MarkdownLite.IMarkdownToken or any type implements it. @Microsoft.DocAsCode.MarkdownLite.IMarkdownContext or any type implements it. Always invoke the best overloaded method (The best is defined by binder ). Engine and engine builder Engine is a set of parser, rewriter and renderer. It can markup a markdown file to html file (or others). But it cannot be invoked in parallel. So we create an engine builder . It defines all the rules of parser, rewriter and renderer. It can create instances when needed. How to customize markdown syntax Define markdown syntax Define markdown: : My label should be rendered as following html: <div id=\"My label\"></div> Select token kind First of all, we should select the context for this rule. And in this goal, the new line is required. So it should be a block token , all of the names for class should contain Block . Define token Create a token class like following: public class MarkdownMyLabelBlockToken : IMarkdownToken { public MarkdownMyLabelBlockToken(IMarkdownRule rule, IMarkdownContext context, string label, SourceInfo sourceInfo) { Rule = rule; Context = context; Label = label; SourceInfo = sourceInfo; } public IMarkdownRule Rule { get; } public IMarkdownContext Context { get; } public string Label { get; } public SourceInfo SourceInfo { get; } } Define rule Create a rule class as following: public class MarkdownMyLabelBlockRule : IMarkdownRule { public virtual string Name => \"My Label\"; public virtual Regex LabelRegex { get; } = new Regex(\"^\\: *([^\\n]+?) *(?:\\n+|$)\"); public virtual IMarkdownToken TryMatch(IMarkdownParser parser, IMarkdownParsingContext context) { var match = LabelRegex.Match(context.CurrentMarkdown); if (match.Length == 0) { return null; } var sourceInfo = context.Consume(match.Length); return new MarkdownMyLabelBlockToken(this, parser.Context, match.Group[1].Value, sourceInfo); } } Define renderer Create a renderer class as following: public class MyRenderer : HtmlRenderer { public virtual StringBuffer Render(IMarkdownRenderer renderer, MarkdownMyLabelBlockToken token, IMarkdownContext context) { return StringBuffer.Empty + \"<div id=\\\"\" + token.Label + \"\\\"></div>\"; } } Define engine builder Create an engine builder class as following: public class MyEngineBuilder : GfmEngineBuilder { public MyEngineBuilder(Options options) : base(options) { BlockRules = BlockRules.Insert(0, new MarkdownMyLabelBlockRule()); } } Markup it! Then use your custom markdown in your code: public string MarkupMyMarkdown(string markdown) { var builder = new MyEngineBuilder(new Options()); var engine = builder.CreateEngine(new MyRender()) return engine.Markup(markdown); }"
  },
  "tutorial/walkthrough/advanced_walkthrough.html": {
    "href": "tutorial/walkthrough/advanced_walkthrough.html",
    "title": "🔧 Walkthrough Advanced: Customize Your Website | DocFX website",
    "keywords": "🔧 Walkthrough Advanced: Customize Your Website Note This topic hasn’t been written yet! You can track the status of this issue through our public GitHub issue tracker. Learn how you can contribute on GitHub. Add more details to an API using a Markdown file. Add cross references. Apply your own styles to the website. Write your own plugins and your own template."
  },
  "tutorial/walkthrough/walkthrough_create_a_docfx_project.html": {
    "href": "tutorial/walkthrough/walkthrough_create_a_docfx_project.html",
    "title": "Walkthrough Part I: Generate a Simple Documentation Website | DocFX website",
    "keywords": "Walkthrough Part I: Generate a Simple Documentation Website By completing this walkthrough, you'll become familiar with the workflow of docfx and the general principle of organizing documents inside docfx . You will finish this walkthrough with a static website that can be published to any host service. Download the files used in this walkthrough here . Step1. Setup DocFX Download docfx from http://dotnet.github.io/docfx/ . Getting Started with docfx describes three ways to install docfx . This walkthrough uses the first one: Use docfx.exe directly. Download docfx.zip and unzip it to D:\\docfx\\ Add D:\\docfx\\ to PATH so that command docfx and be directly called from everywhere for convenience. (for example, for Windows, setx PATH \"%PATH%;D:\\docfx\\\" Step2. Init a DocFX project Create a new folder D:\\docfx_walkthrough Start Command Line under D:\\docfx_walkthrough Call docfx init -q . This command generates a docfx_project folder with the default docfx.json file under it. docfx.json is the configuration file docfx uses to generate documentation. -q option means generating the project quietly using default value, you can also try docfx init and follow the instructions to provide your own settings. Step3. Build our website Run command docfx docfx_project/docfx.json . Note that a new subfolder _site is generated under that folder. This is where the static website is generated. Step4. Preview our website The generated static website can be published to GitHub pages, Azure websites, or your own hosting services without any further changes. You can also run command docfx serve docfx_project/_site to preview the website locally. If port 8080 is not in use, docfx will host _site under http://localhost:8080 . If 8080 is in use, you can use docfx serve _site -p <port> to change the port to be used by docfx . Congrats! You can now see a simple website similar to: Step5. Add a set of articles to the website Place more .md files to articles , e.g. details1.md , details2.md , details3.md . If the file references any resources, put those resources into the images folder. In order to organize these articles, we add these files into toc.yml under articles subfolder. The content of toc.yml is as below: - name: Introduction href: intro.md - name: Details 1 href: details1.md - name: Details 2 href: details2.md - name: Details 3 href: details3.md So now our folder layout is: |- index.md |- toc.yml |- articles | |- intro.md | |- details1.md | |- details2.md | |- details3.md | |- toc.yml |- images |- details1_image.png Run Step3 and Step4 again, and the website is now: . Notice that more items are added to the sidebar for Articles nav page. The title inside the sidebar is exactly what we set in the toc.yml inside articles subfolder. Conclusion In this walkthrough, we build a website from a set of .md files. We call these .md files Conceptual Documentation . In walkthrough part 2, we will learn to add API Documentation to our website. The API Documentation is extracted directly from .NET source code. In a series of advanced walkthroughs, we will learn advanced concepts in docfx , such as cross reference between articles, external reference to other documentations, etc. We will also learn to customize our websites, from theme to layout to metadata extraction. Read more Walkthrough Part II: Adding API Documentation to the Website Walkthrough Advanced: Customize Your Website"
  },
  "tutorial/walkthrough/walkthrough_create_a_docfx_project_2.html": {
    "href": "tutorial/walkthrough/walkthrough_create_a_docfx_project_2.html",
    "title": "Walkthrough Part II: Adding API Documentation to the Website | DocFX website",
    "keywords": "Walkthrough Part II: Adding API Documentation to the Website After completing Walkthrough Part I: Generate a Simple Documentation Website , we build a website from a set of .md files. We call it Conceptual Documentation . In this walkthrough, we will learn to build website from .NET source code, which is called API Documentation . We will also integrate Conceptual Documentation and API Documentation into one website, so that we can navigate from Conceptual to API , or API to Conceptual seamlessly. Download the files used in this walkthrough here . After completing walkthrough part I, our D:\\docfx_walkthrough\\docfx_project folder is in the following structure: |- index.md |- toc.yml |- articles | |- intro.md | |- details1.md | |- details2.md | |- details3.md | |- toc.yml |- images |- details1_image.png |- api |- index.md |- toc.yml Step1. Add a C# project Create a subfolder src under D:\\docfx_walkthrough\\docfx_project . Open Visual Studio Community 2015 (or an above version) and create a C# Class Library HelloDocfx under folder src . In the Class1.cs , add some comments and methods to this class, similar to: namespace HelloDocfx { /// <summary> /// Hello this is **Class1** from *HelloDocfx* /// </summary> public class Class1 { private InnerClass _class; public int Value { get; } /// <summary> /// This is a ctor /// </summary> /// <param name=\"value\">The value of the class</param> public Class1(int value) { Value = value; } public double ConvertToDouble() { return Value; } /// <summary> /// A method referencing a inner class /// </summary> /// <param name=\"name\">The name</param> /// <param name=\"inner\">A inner class with type <seealso cref=\"InnerClass\"/></param> public void SetInnerClass(string name, InnerClass inner) { inner.Name = name; _class = inner; } public class InnerClass { public string Name { get; set; } } } } Step2. Generate metadata for the C# project Calling docfx metadata under D:\\docfx_walkthrough\\docfx_project . docfx metadata is a sub-command registered in docfx , and it reads configuration in the metadata section from docfx.json . [ \"src/**.csproj\" ] in metadata/src/files tells docfx to search all the csproj from src subfolder to generate metadata. \"metadata\": [ { \"src\": [ { \"files\": [ \"src/**.csproj\" ], \"exclude\": [ \"**/bin/**\", \"**/obj/**\", \"_site/**\" ] } ], \"dest\": \"api\" } ] This generates several YAML files in the api folder. The YAML file contains the data model extracted from C# source code file. YAML is the metadata format used in docfx . General Metadata Spec defines the general schema, and .NET Metadata Spec defines the metadata schema for .NET languages that docfx can consume. |- HelloDocfx.Class1.InnerClass.yml |- HelloDocfx.Class1.yml |- HelloDocfx.yml |- toc.yml Step3. Build and preview our website Running the command docfx . docfx reads docfx.json and execute subcommands defined in the config file one by one. Our docfx.json defines metadata and build , so by running docfx , we are actually executing docfx metadata and docfx build , and thus generating the website. Run docfx serve _site , and the website is now: . Conclusion In this walkthrough, we build a website containing both Conceptual Documentation and API Documentation . In the upcoming series of advanced walkthroughs, we will learn advanced concepts in docfx , such as cross reference between articles, external reference to other documentations, etc. We will also learn to customize our websites, from theme to layout to metadata extraction. Read more Walkthrough Part I: Generate a Simple Documentation Website Walkthrough Advanced: Customize Your Website"
  },
  "tutorial/walkthrough/walkthrough_overview.html": {
    "href": "tutorial/walkthrough/walkthrough_overview.html",
    "title": "Walkthrough Overview | DocFX website",
    "keywords": "Walkthrough Overview By completing these walkthroughs, you'll create a static website, containing both Conceptual Documentation which comes from .md files and API Documentation which comes from .NET source code. You'll also be able to customize your website with your own styles and templates! List of Articles Walkthrough Part I: Generate a Simple Documentation Website Walkthrough Part II: Adding API Documentation to the Website Walkthrough Advanced: Customize Your Website"
  },
  "README.html": {
    "href": "README.html",
    "title": "| DocFX website",
    "keywords": "Documentation project uses docfx.msbuild nuget package to generate documentation for docfx project, along with conceputal files, with docfx.json to provide configuration for docfx ."
  },
  "guideline/csharp_coding_standards.html": {
    "href": "guideline/csharp_coding_standards.html",
    "title": "C# Coding Standards | DocFX website",
    "keywords": "C# Coding Standards Introduction The C# Coding Standards will be used in conjunction with customized versions of StyleCop and FxCop [ TODO ] during both development and build process. This will help ensure that all developers on the team are in a consistent manner. \"Any fool can write code that a computer can understand. Good programmers write code that humans understand\". Martin Fowler. Refactoring: Improving the design of existing code. Purpose This section defines a set of C# coding standards to be used by the DocFX build team to guarantee maximum legibility, reliability, re-usability and homogeneity of our code. Each section is marked Mandatory or Recommended . Mandatory sections will be enforced during code reviews as well as tools like StyleCop and FxCop , and code will not be considered complete until it is compliant. Scope This section contains general C# coding standards that can be applied to any type of application developed in C#, based upon Framework Design Guidelines . This section is not intended to be a tutorial on C#. Instead, it includes a set of limitations and recommendations focused on clarifying the development. Tools ReSharper is a useful third-party code cleanup and style tool. StyleCop analyzes C# source code to enforce a set of style and consistency rules and has been integrated into many third-party development tools such as ReSharper. FxCop is an application that analyzes managed code assemblies (code that targets the .NET Framework common language runtime) and reports information about the assemblies, such as possible design, localization, performance, and security improvements. Highlights of Coding Standards This section is not intended to give a summary of all the coding standards enabled by our customized StyleCop, but to give a highlight of some rules one will possibly meet in daily coding life. It also provides some coding standards that are recommended but not mandatory (that is, not enabled by StyleCop). File Layout (Recommended) Only one public class is allowed per file. The file name derives from the class name. Class : Observer Filename: Observer.cs Class Definition Order (Mandatory) The class definition contains class members in the following order, from less restricted scope (public) to more restrictive (private): ~ Nested types, e.g. classes, enum, struct, etc. ~ Non-private nested types are not allowed. Field members (for example, member variables, const, etc.) Member functions Constructors Finalizer (Do not use unless absolutely necessary) Methods (Properties, Events, Operations, Overridables and Static) Private nested types Naming (Mandatory) DO use plural form for namespaces DO use PascalCasing for all public member, type, and namespace names consisting of multiple words. PropertyDescriptor HtmlTag IOStream Note A special case is made for two-letter acronyms in which both letters are capitalized, e.g. IOStream DO use camelCasing for parameter names. propertyDescriptor htmlTag ioStream DO start with underscore for private fields: private readonly Guid _userId = Guid.NewGuid(); DO start static readonly field and constant names with capitalized case private static readonly IEntityAccessor EntityAccessor = null; private const string MetadataName = \"MetadataName\"; DO NOT capitalize each word in so-called closed-form compound words . DO use Async suffix in the asynchronous method names to notice people how to use it properly public async Task<string> LoadContentAsync() { ... } Formatting (Mandatory) DO use spaces over tabs, and always show all spaces/tabs in IDE Tips Visual Studio > Tools > Options... > Text Editor > C# > Tabs > Insert spaces (Tab size: 4) Visual Studio > Edit > Advanced > View White Space (Ctrl+R, Ctrl+W) DO add using inside namespace declaration namespace Microsoft.Content.Build.BuildWorker.UnitTest { using System; } DO add a space when: for (var i = 0; i < 1; i++) if (a == b) Performace Consideration DO use sealed for private classes if they are not to be inherited. DO add readonly to fields if they do not tend to be changed. DO use static methods if it is not instance relevant. DO use RegexOptions.Compiled for readonly Regex . Cross-platform coding Our code can and should support multiple operating systems in addition to Windows. Code should be sensitvie to the differences between Operating Systems. Here are some specifics to consider: DO use Enviroment.NewLine instead of hard-coding the line break, as Windows uses \\r\\n and OSX/Linux uses \\n . Note Be aware that these line-endings may cause problems in code when using @\"\" text blocks with line breaks, e.g.: var x = @\"line1 line2\"; DO use Path.Combine() or Path.DirectorySeparatorChar to separate directories. If this is not possible (such as in scripting), use a forward slash / . Windows is more forgiving than Linux in this regard. Unit tests and functional tests Assembly naming The unit tests for the Microsoft.Foo assembly live in the Microsoft.Foo.Tests assembly. The functional tests for the Microsoft.Foo assembly live in the Microsoft.Foo.FunctionalTests assembly. In general there should be exactly one unit tests assembly for each product runtime assembly. In general there should be one functional tests assembly per repo. Exceptions can be made for both. Unit test class naming Test class names end with Test suffix and live in the same namespace as the class being tested. For example, the unit tests for the Microsoft.Foo.Boo class would be in a Microsoft.Foo.BooTest class in the unit tests assembly Microsoft.Foo.Tests . Unit test method naming Unit test method names must be descriptive about what developers are testing, under what conditions, and what the expectations are . Pascal casing and underscores can be used to improve readability. The following test names are correct: PublicApiArgumentsShouldHaveNotNullAnnotation Public_api_arguments_should_have_not_null_annotation The following test names are incorrect: Test1 Constructor FormatString GetData Unit test structure The contents of every unit test should be split into three distinct stages (arrange, act and assert), optionally separated by these comments: // Arrange // Act // Assert The crucial thing here is the Act stage is exactly one statement. That one statement calls only the one method that you are trying to test. Keeping that one statement as simple as possible is also very important. For example, this is not ideal: int result = myObj.CallSomeMethod(GetComplexParam1(), GetComplexParam2(), GetComplexParam3()); This style is not recommended because too much can go wrong in this one statement. All the GetComplexParamN() calls can throw exceptions for a variety of reasons unrelated to the test itself. It is thus unclear to someone running into a problem why the failure occurred. The ideal pattern is to move the complex parameter building into the Arrange section: // Arrange P1 p1 = GetComplexParam1(); P2 p2 = GetComplexParam2(); P3 p3 = GetComplexParam3(); // Act int result = myObj.CallSomeMethod(p1, p2, p3); // Assert Assert.AreEqual(1234, result); Now the only reason the line with CallSomeMethod() can fail is if the method itself throws an error. Testing exception messages Testing the specific exception message in a unit test is important. This ensures that the desired exception is being tested rather than a different exception of the same type. In order to verify the exact exception, it is important to verify the message. // Act var ex = Assert.Throws<InvalidOperationException>(() => fruitBasket.GetBananaById(-1)); // Assert Assert.Equal(\"Cannot load banana with negative identifier.\", ex.Message); Use xUnit.net's plethora of built-in assertions xUnit.net includes many kinds of assertions – please use the most appropriate one for your test. This makes the tests much more readable and also allows the test runner to report the best possible errors (whether it's local or the CI machine). For example, these are bad: Assert.Equal(true, someBool); Assert.True(\"abc123\" == someString); Assert.True(list1.Length == list2.Length); for (int i = 0; i < list1.Length; i++) { Assert.True( String.Equals( list1[i], list2[i], StringComparison.OrdinalIgnoreCase)); } These are good: Assert.True(someBool); Assert.Equal(\"abc123\", someString); // built-in collection assertions! Assert.Equal(list1, list2, StringComparer.OrdinalIgnoreCase); Parallel tests By default all unit test assemblies should run in parallel mode, which is the default. Unit tests shouldn't depend on any shared state, and so should generally be runnable in parallel. If tests fail in parallel, the first thing to do is to figure out why; do not just disable parallel testing! For functional tests, you can disable parallel tests."
  },
  "guideline/engineering_guidelines.html": {
    "href": "guideline/engineering_guidelines.html",
    "title": "Engineering Guidelines | DocFX website",
    "keywords": "Engineering Guidelines Basics Copyright header and license notice All source code files require the following exact header according to its language (please do not make any changes to it). extension: .cs // Copyright (c) Microsoft. All rights reserved. // Licensed under the MIT license. See LICENSE file in the project root for full license information. extension: .js // Copyright (c) Microsoft. All rights reserved. Licensed under the MIT license. See LICENSE file in the project root for full license information. extension: .css /* Copyright (c) Microsoft Corporation. All Rights Reserved. Licensed under the MIT License. See License.txt in the project root for license information. */ extension: .tmpl , .tmpl.partial {{!Copyright (c) Microsoft. All rights reserved. Licensed under the MIT license. See LICENSE file in the project root for full license information.}} External dependencies This refers to dependencies on projects (that is, NuGet packages) outside of the docfx repo, and especially outside of Microsoft. Adding new dependencies requires additional approval. Current approved dependencies are: Newtonsoft.Json Jint HtmlAgilityPack Nustache YamlDotNet Code reviews and checkins To help ensure that only the highest quality code makes its way into the project, please submit all your code changes to GitHub as PRs. This includes runtime code changes, unit test updates, and deployment scripts. For example, sending a PR for just an update to a unit test might seem like a waste of time but the unit tests are just as important as the product code. As such, reviewing changes to unit tests is just as important. The advantages are numerous: Improving code quality; increasing visibility on changes and their potential impact; avoiding duplication of effort; and creating general awareness of progress being made in various areas. In general a PR should be signed off(using the 👍 emoticon) by the owner of that code. To commit the PR to the repo, do not use the Big Green Button . Instead, do a typical push that you would use with Git (for example, local pull, rebase, merge or push). Source Code Management Branch strategy In general: master has the code for the latest release on NuGet.org. (e.g. 1.0.0 , 1.1.0 ) dev has the code that is being worked on but that we have not yet released. This is the branch into which developers normally submit pull requests and merge changes into. We run daily CI towards dev branch and generate pre-release nuget package, e.g. 1.0.1-alpha-9-abcdefsd . Solution and project folder structure and naming Solution files go in the repo root. The default entry point is All.sln . Every project also needs a project.json and a matching .xproj file. This project.json is the source of truth for a project's dependencies and configuration options. The solution needs to contain solution folders that match the physical folder ( src , test , tools , etc.). Assembly naming pattern The general naming pattern is Microsoft.DocAsCode.<area>.<subarea> . Unit tests We use xUnit.net for all unit testing. Coding Standards Please refer to C# Coding standards for detailed guideline for C# coding standards. TODO Template Coding standards TODO Template Preprocess JS Coding standards"
  },
  "spec/docfx_build_manifest_file.html": {
    "href": "spec/docfx_build_manifest_file.html",
    "title": "Data structure for manifest file generated by docfx build | DocFX website",
    "keywords": "Data structure for manifest file generated by docfx build After docfx build , docfx generates a manifest file in JSON format in the root output folder, listing some basic information about the set of files that docfx build handles. Before DocFX version 1.7, the manifest file is an Array of items. Then DocFX realizes that there are also global properties manifest file consumers care about, for example, the list of TOC files that DocFX processed. However, it is hard to add properties to an Array model. So since version 1.8, DocFX introduces a new Object model for the manifest file. For backward compatibility, in version 1.8, DocFX generates both Array model to-be-obsoleted and the new Object model. In version 1.9, manifest file in Array model will be removed . Below table shows the difference between manifest file in Array model and manifest file in Object model. ---- File Name Data Model Old Array Model .manifest Array model New Object Model .manifest.json Object model The obsoleted Array model Array model contains a list of Manifest Item s. The new Object model Current supported properties for the Object model is listed as below: Property Name Type Description files Array of Manifest Item Array of Manifest Item model homepages Array of Homepage Array of Homepage model Manifest Item model Property Name Type Description type string The documentType is generated by plugins or specified to each file using Yaml Header . Currently by default DocFX generates following document type s: ManagedReference , Conceptual , RestApi , Resource , toc . original string Specifies the input file path to the root folder of the Git repository. It is the absolute file path if the file is not inside a Git repository. outputFiles Dictionary<string,string> For each output file, the key is the extension of the transformed file, the extension is determined by the template it applies to. And the value is the output file path relative to the manifest file. Homepage model Property Name Type Description tocPath string Specifies the output TOC file path relative to the manifest file. homepage string Specifies the homepage for current TOC with file path relative to the manifest file."
  },
  "spec/docfx_design_spec.html": {
    "href": "spec/docfx_design_spec.html",
    "title": "docfx Design Spec | DocFX website",
    "keywords": "docfx Design Spec 0. Terms Term Description DFM DocFX Flavored Markdown API The API generated from source code Overwrite Files The files with YAML header used to override YAML files when uid matches. 1. Scenarios docfx should support the following scenarios: Source Code => Website Conceptual => Website YAML files => Website 2. Architecture 3. Feature List Support for DocFX Flavored Markdown Ability to parse TOC.json/TOC.yml/TOC.md Custom template naming: {type}.{extension}.tmpl under folder {templateName} 4. Open Issues Should we support other conceptual file format, for example, RST? ==> How to parse? How do you know which link to replace to html, and which not? ==>"
  },
  "spec/docfx_flavored_markdown.html": {
    "href": "spec/docfx_flavored_markdown.html",
    "title": "DocFX Flavored Markdown | DocFX website",
    "keywords": "DocFX Flavored Markdown DocFX supports \"DocFX Flavored Markdown,\" or DFM. It is 100% compatible with GitHub Flavored Markdown , and adds some additional functionality, including cross reference and file inclusion. Yaml Header Yaml header in DFM is considered as the metadata for the Markdown file. It will transform to yamlheader tag when processed. Yaml header MUST be the first thing in the file and MUST take the form of valid YAML set between triple-dashed lines. Here is a basic example: --- uid: A.md title: A --- Cross Reference Cross reference allows you to link to another topic by using its unique identifier (called UID) instead of using its file path. For conceptual Markdown files UID can be defined by adding a uid metadata in YAML header: --- uid: uid_of_the_file --- This is a conceptual topic with `uid` specified. For reference topics, UIDs are auto generated from source code and can be found in generated YAML files. You can use one of the following syntax to cross reference a topic with UID defined: Markdown link: [link_text](xref:uid_of_the_topic) Auto link: <xref:uid_of_the_topic> Shorthand form: @uid_of_the_topic All will render to: <a href=\"url_of_the_topic\">link_text</a> If link_text is not specified, DocFX will extract the title from the target topic and use it as the link text. For more information, see cross reference . File Inclusion DFM adds syntax to include other file parts into current file, the included file will also be considered as in DFM syntax. NOTE that YAML header is NOT supported when the file is an inclusion. There are two types of file inclusion: Inline and block, as similar to inline code span and block code. Inline Inline file inclusion is in the following syntax, in which <title> stands for the title of the included file, and <filepath> stands for the file path of the included file. The file path can be either absolute or relative. <filepath> can be wrapped by ' or \" . NOTE that for inline file inclusion, the file included will be considered as containing only inline tags, for example, ###header inside the file will not transfer since <h3> is a block tag, while [a](b) will transform to <a href='b'>a</a> since <a> is an inline tag. ...Other inline contents... [!include[<title>](<filepath>)] Block Block file inclusion must be in a single line and with no prefix characters before the start [ . Content inside the included file will transform using DFM syntax. [!include[<title>](<filepath>)] Section definition User may need to define section. Mostly used for code table. Give an example below. > [!div class=\"tabbedCodeSnippets\" data-resources=\"OutlookServices.Calendar\"] > ```cs > <cs code text> > ``` > ```javascript > <js code text> > ``` The above blockquote Markdown text will transform to section html as in the following: <div class=\"tabbedCodeSnippets\" data-resources=\"OutlookServices.Calendar\"> <pre><code>cs code text</code></pre> <pre><code>js code text</code></pre> </div> Code Snippet Allows you to insert code with code language specified. The content of specified code path will expand. [!code-<language>[<name>](<codepath><queryoption><queryoptionvalue> \"<title>\")] <language> can be made up of any number of character and '-'. However, the recommended value should follow Highlight.js language names and aliases . <codepath> is the relative path in file system which indicates the code snippet file that you want to expand. <queryoption> and <queryoptionvalue> are used together to retrieve part of the code snippet file in the line range or tag name way. We have 2 query string options to represent these two ways: query string using # query string using ? 1. line range #L{startlinenumber}-L{endlinenumber} ?start={startlinenumber}&end={endlinenumber} 2. tagname #{tagname} ?name={tagname} 3. multiple region range Unsupported ?range={rangequerystring} 4. highlight lines Unsupported ?highlight={rangequerystring} 5. dedent Unsupported ?dedent={dedentlength} In ? query string, the whole file will be included if none of the first three option is specified. If dedent isn't specified, the maximum common indent will be trimmed automatically. <title> can be omitted. Code Snippet Sample [!code-csharp[Main](Program.cs)] [!code[Main](Program.cs#L12-L16 \"This is source file\")] [!code-vb[Main](../Application/Program.vb#testsnippet \"This is source file\")] [!code[Main](index.xml?start=5&end=9)] [!code-javascript[Main](../jquery.js?name=testsnippet)] [!code[Main](index.xml?range=2,5-7,9-) \"This includes the lines 2, 5, 6, 7 and lines 9 to the last line\"] [!code[Main](index.xml?highlight=2,5-7,9-) \"This includes the whole file with lines 2,5-7,9- highlighted\"] Tag Name Representation in Code Snippet Source File DFM currently only supports the following <language> values to be able to retrieve by tag name: C#: cs, csharp VB: vb, vbnet C++: cpp, c++ F#: fsharp XML: xml Html: html SQL: sql Javascript: javascript Note (Warning/Tip/Important) Using specific syntax inside block quote to indicate the following content is Note. > [!NOTE] > <note content> > [!WARNING] > <warning content> The above content will be transformed to the following html: <div class=\"NOTE\"> <h5>NOTE</h5> <p>note content</p> </div> <div class=\"WARNING\"> <h5>WARNING</h5> <p>WARNING content</p> </div>"
  },
  "spec/docfx_incremental.html": {
    "href": "spec/docfx_incremental.html",
    "title": "Doc-as-code: DocFx.exe Incremental Build Specification | DocFX website",
    "keywords": "Doc-as-code: DocFx.exe Incremental Build Specification This documentation describes the implementation of incrementally extracting metadata from source. Currently we are using Roslyn to compile and analyse source code on the fly. When input sources are large, it may take minutes to load and process the files. To speed up the extraction, previous extracted details are saved to cache for further reference. There are two level caches in current implementation. First one is called Application Level cache, and the other one is Project level cache. Application level cache is saved in file %LocalAppData%/xdoc/cache . For Project level cache, a. If input sources are supported project files, e.g. .csproj or .vbproj files, Project level cache is located in file obj/xdoc/.cache under the same folder of the project file. b. If input sources are supported source code files, e.g. .cs or .vb files, Project level cache is located in file obj/xdoc/.cache under the same folder of the alphabetically first source code file. The cache file contains key-value pairs saved in JSON format. The key is the normalized input source code files, and the data structure for the value is as below: Property Description TriggeredUTCTime The UTC time when the action is triggered CompletedUTCTime The UTC time when the action is completed OutputFolder The output folder for the extracted result RelativeOutputFiles The paths of the extracted results related to the OutputFolder CheckSum The MD5 checksum calculated for all the extracted results Detailed Steps are described below: For each input solution/project/source files, get most latest LastModifiedTime . a. For solution, get LastModifiedTime for the solution file, and containing projects b. For project, get LastModifiedTime for the project file, project references, assembly references and containing documents. c. For source files, get LastModifiedTime for the files Normalize project list, check if Application level cache for these project list exists. Compare TriggeredUTCTime with the LastModifiedTime fetched in #1, and check if checksum remains unchanged for output files. If is, copy result files to output folder. Otherwise, continue to #3. For each supported solution/project/source code files, Step 1 . Check if Project level cache exists. If not, go to Step 4 . Step 2 . Compare TriggeredUTCTime with the LastModifiedTime fetched in #1, and check if checksum remains unchanged for output files. If not, go to Step 3 . Step 3 . Generate YAML metadata for current project and save to Project level cache. Read YAML metadata for each project, and merge with others following rules below: Rule 1 . For namespace , if uid equals, append . Rule 2 . For other type, if uid equals, override . Save result, and update *Application level cache."
  },
  "spec/metadata_dotnet_spec.html": {
    "href": "spec/metadata_dotnet_spec.html",
    "title": "DocFx: Metadata Format for .NET Languages | DocFX website",
    "keywords": "DocFx: Metadata Format for .NET Languages 0. Introduction 0.1 Goal and Non-goals 0.2 Terminology 1. Items The following .NET elements are defined as items in metadata: Namespaces Types, including class, struct, interface, enum, delegate Type members, including field, property, method, event Other elements such as parameters and generic parameters are not standalone items , they're part of other items . 2. Identifiers 2.1 Unique Identifiers For any item in .NET languages, its UID is defined by concatenating its parent 's UID and its own ID with a dot. The ID for each kind of item is defined in following sections. The basic principle here is to make ID format close to source code and easy for human reading. UID is similar to the document comment id, which is started with type prefix, for example, T: , or M: , but UID do not. There MUST NOT be any whitespace between method name, parentheses, parameters, and commas. 2.2 Spec Identifiers Spec identifier is another form of UID . It can spec a generic type with type arguments (for example, for parameters, return types or inheritances) and these UID s are unique in one yaml file. It is a simple modified Unique Identifiers, when it contains generic type arguments, it will use {Name} instead `N . For type parameter, it will be {Name} . And it also supports array and pointer. Example 2.2 Spec Identifier C#: namespace Foo { public class Bar { public unsafe List<String> FooBar<TArg>(int[] arg1, byte* arg2, TArg arg3, List<TArg[]> arg4) { return null; } } } YAML: references: - uid: System.Collections.Generic.List{System.String} - uid: System.Int32[] - uid: System.Byte* - uid: {TArg} - uid: System.Collections.Generic.List{{TArg}[]} 3. Namespaces For all namespaces, they are flat, e.i. namespaces do not have the parent namespace. So for any namespace, ID is always same with its UID . Example 3 Namespace C#: namespace System.IO { } YAML: uid: System.IO id: System.IO name: System.IO fullName: System.IO The children of namespace are all the visible types in the namespace. 4. Types Types include classes, structs, interfaces, enums, and delegates. They have following properties: summary, remarks, syntax, namespace, assemblies, inheritance. The parents of types are namespaces. The children of types are members. ID ID for a type is also its name . Example 4 Type C#: namespace System { public class String {} public struct Boolean {} public interface IComparable {} public enum ConsoleColor {} public delegate void Action(); } YAML: - uid: System.String id: String name.csharp: String fullName.csharp: System.String - uid: System.Boolean id: Boolean name.csharp: Boolean fullName.csharp: System.String - uid: System.IComparable id: IComparable name.csharp: IComparable fullName.csharp: System.IComparable - uid: System.ConsoleColor id: ConsoleColor name.csharp: ConsoleColor fullName.csharp: System.ConsoleColor - uid: System.Action id: Action name.csharp: Action fullName.csharp: System.Action 4.1 ID for Nested Types For nested types, ID is defined by concatenating the ID of all its containing types and the ID of itself, separated by a dot. The parent type of a nested type is its containing namespace, rather than its containing type. Example 4.1 Nested type C#: namespace System { public class Environment { public enum SpecialFolder {} } } YAML: uid: System.Environment.SpecialFolder id: Environment.SpecialFolder name.csharp: Environment.SpecialFolder fullName.csharp: System.Environment.SpecialFolder 4.2 Inheritance Only class contains inheritance, and the inheritance is a list of spec id. Example 4.2 Inheritance C#: namespace System.Collections.Generic { public class KeyedByTypeCollection<TItem> : KeyedCollection<Type, TItem> { } } YAML: uid : System.Collections.Generic.KeyedByTypeCollection`1 inheritance: - System.Collections.ObjectModel.KeyedCollection{System.Type,{TItem}} - System.Collections.ObjectModel.Collection{{TItem}} - System.Object 4.3 Syntax The syntax part for type contains declaration, and descriptions of type parameters for different languages. For delegates, it also contains descriptions of parameters and a return type. 5. Members Members include fields, properties, methods, and events. They have the following properties: summary, remarks, exceptions, and syntax. The parents of members are types. Members never have children, and all parameter types or return types are spec id. 5.1 Constructors The ID of a constructor is defined by #ctor , followed by the list of the UIDs of its parameter types: When a constructor does not have parameter, its ID MUST NOT end with parentheses. The syntax part for constructors contains a special language declaration, and descriptions of parameters. Example 5.1 Constructor C#: namespace System { public sealed class String { public String(); public String(char[] chars); } } YAML: - uid: System.String.#ctor id: #ctor name.csharp: String() fullName.csharp: System.String.String() - uid: System.String.#ctor(System.Char[]) id: #ctor(System.Char[]) name.csharp: String(Char[]) fullName.csharp: System.String.String(System.Char[]) 5.2 Methods The ID of a method is defined by its name, followed by the list of the UIDs of its parameter types: method_name(param1,param2,...) When a method does not have parameter, its ID MUST end with parentheses. The syntax part for method contains a special language declaration, and descriptions of type parameters for generic method, descriptions of parameters and return type. Example 5.2 Method C#: namespace System { public sealed class String { public String ToString(); public String ToString(IFormatProvider provider); } } YAML: - uid: System.String.ToString id: ToString name.csharp: ToString() fullName.csharp: System.String.ToString() - uid: System.String.ToString(System.IFormatProvider) id: ToString(System.IFormatProvider) name.csharp: ToString(IFormatProvider) fullName.csharp: System.String.ToString(System.IFormatProvider) 5.2.1 Explicit Interface Implementation The ID of an explicit interface implementation (EII) member MUST be prefixed by the UID of the interface it implements and replace . to # . Example 2.6 Explicit interface implementation (EII) C#: namespace System { using System.Collections; public sealed class String : IEnumerable { IEnumerator IEnumerable.GetEnumerator(); } } YAML: - uid: \"System.String.System#Collections#IEnumerable#GetEnumerator\" id: \"System#Collections#IEnumerable#GetEnumerator\" name.csharp: IEnumerable.GetEnumerator() fullName.csharp: System.String.System.Collections.IEnumerable.GetEnumerator() 5.4 Operator Overloads The IDs of operator overloads are same with the metadata name (for example, op_Equality ). The names of operator overloads are similar to MSDN, just remove op_ from the metadata name of the method. For instance, the name of the equals ( == ) operator is Equality . Type conversion operator can be considered a special operator whose name is the UID of the target type, with one parameter of the source type. For example, an operator that converts from string to int should be Explicit(System.String to System.Int32) . The syntax part for methods contains a special language declaration, descriptions of parameters and return type. Example 5.4 Operator overload namespace System { public struct Decimal { public static implicit operator Decimal(Char value); } public sealed class String { public static bool operator ==(String a, String b); } } YAML: - uid: System.Decimal.op_Implicit(System.Char to System.Decimal) id: op_Implicit(System.Char to System.Decimal) name.csharp: Implicit(Char to Decimal) fullName.csharp: System.Decimal.Implicit(System.Char to System.Decimal) - uid: System.String.op_Equality(System.String,System.String) id: op_Equality(System.String,System.String) name.csharp: Equality(String,String) fullName.csharp: System.String.Equality(System.String,System.String) Please check overloadable operators for all overloadable operators. 5.5 Field, Property or Event The ID of field, property or event is its name. The syntax part for field contains a special language declaration and descriptions of field type. For property, it contains a special language declaration, descriptions of parameters, and return type. For event, it contains a special language declaration and descriptions of event handler type. Example 5.5 Field, Property and Event C#: namespace System { public sealed class String { public static readonly String Empty; public int Length { get; } } public static class Console { public static event ConsoleCancelEventHandler CancelKeyPress; } } YAML: - uid: System.String.Empty id: Empty name.csharp: Empty fullName.csharp: System.String.Empty - uid: System.String.Length id: Length name.csharp: Length fullName.csharp: System.String.Length - uid: System.Console.CancelKeyPress id: CancelKeyPress name.csharp: CancelKeyPress fullName.csharp: System.Console.CancelKeyPress 5.6 Indexer Indexer operator's name is metadata name, by default, it is Item , with brackets and parameters. Example 5.6 Indexer namespace System.Collections { public interface IList { object this[int index] { get; set; } } } YAML: - uid: \"System.Collections.IList.Item[System.Int32]\" id: \"Item[System.Int32]\" name.csharp: Item[Int32] fullName.csharp: System.Collections.IList.Item[System.Int32] 6. Generics The ID of a generic type is its name with followed by `n , n and the count of generic type count, which is the same as the rule for document comment ID. For example, Dictionary`2 . The ID of a generic method uses postfix ``n , n is the count of in method parameters, for example, System.Tuple.Create``1(``0) . Example 2.7 Generic namespace System { public static class Tuple { public static Tuple<T1> Create<T1>(T1 item1); public static Tuple<T1, T2> Create<T1, T2>(T1 item1, T2 item2); } } YAML: - uid: System.Tuple.Create``1(``0) id: Create``1(``0) name.csharp: Create<T1>(T1) fullName.csharp: System.Tuple.Create<T1>(T1) - uid: System.Tuple.Create``2(``0,``1) id: Create``2(``0,``1) name.csharp: Create<T1,T2>(T1,T2) fullName.csharp: System.Tuple.Create<T1,T2>(T1,T2) 7. Reference The reference contains the following members: name, fullName, summary, isExternal, href, and more. The UID in reference can be a Spec Id , then it contains one more member: spec. The spec in reference is very like a list of lightweight references, it describes how to compose the generic type in some special language. Example 7 spec for references YAML: references: - uid: System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.Int32}} name.csharp: Dictionary<String, List<Int32>> fullName.csharp: System.Collections.Generic.Dictionary<System.String, System.Collections.Generic.List<System.Int32>> spec.csharp: - uid: System.Collections.Generic.Dictionary`2 name: Dictionary fullName: System.Collections.Generic.Dictionary isExternal: true - name: < fullName: < - uid: System.String name: String fullName: System.String isExternal: true - name: ', ' fullName: ', ' - uid: System.Collections.Generic.List`1 name: List fullName: System.Collections.Generic.List isExternal: true - name: < fullName: < - uid: System.Int32 name: Int32 fullName: System.Int32 isExternal: true - name: '>' fullName: '>' - name: '>' fullName: '>'"
  },
  "spec/metadata_format_spec.html": {
    "href": "spec/metadata_format_spec.html",
    "title": "Doc-as-Code: Metadata Format Specification | DocFX website",
    "keywords": "Doc-as-Code: Metadata Format Specification 0. Introduction 0.1 Goals and Non-goals The goal of this document is to define a general format to describe language metadata for programming languages. The language metadata is designed to be language agnostic and support multiple programming language in a single metadata file. The main user scenario for language metadata is to generate reference documentation, so this document will discuss how to optimize metadata format for documentation rendering. This document does NOT discuss details of metadata format implementation of a specific programming language. 0.2 Terminology The key words MUST , MUST NOT , REQUIRED , SHALL , SHALL NOT , SHOULD , SHOULD NOT , RECOMMENDED , MAY , and OPTIONAL in this document are to be interpreted as described in RFC 2119 . Words in italic imply they are terms defined in an earlier section of this document. 1. Items and Identifiers 1.1 Items Item is the basic unit of metadata format. From documentation perspective, each item represents a \"section\" in the reference documentation. This \"section\" is the minimum unit that you can cross reference to, or customize in layout and content. When implementing the metadata format for your own language, you can decide which elements are items . For example, usually namespaces, classes, and methods are items . However, you can also make smaller elements such as parameters be items if you want them to be referenceable and customizable. Items can be hierarchical. One item can have other items as children . For example, in C#, namespaces and classes can have classes and/or methods as children . 1.2 Identifiers Each item has an identifier (ID) which is unique under its parent. As we're targeting to support multiple languages, there is no restrictions as to which characters are not allowed in identifiers. However, to make identifiers easier to recognize and resolve in Markdown, it's not RECOMMENDED to have whitespaces in identifiers. Markdown processor MAY implement some algorithm to tolerate whitespaces in handwritten Markdown. (Leading and trailing spaces MUST be removed from identifier.) Identifier MUST be treated as case-sensitive when comparing equality. Each item has a unique identifier (UID) which is globally unique. A UID is defined as follows: If an item does not have a parent , its UID is its ID . Otherwise, its UID is the combination of the UID of its parent , a separator and the ID of the item itself. Valid separators are . , : , / and \\ . For example, for a class String under namespace System , its ID is String and UID is System.String . Given the above definition, an item 's UID MUST starts with the UID of its parent (and any of its ancestors) and ends with the ID of itself. This is useful to quickly determine whether an item is under another item . 1.3 Alias Identifier could be very long, which makes it difficult to write by hand in Markdown. For example, it's easy to create a long ID in C# like this: Format(System.IFormatProvider,System.String,System.Object,System.Object) We can create short alias for items so that they can be referenced easily. Alias is same as ID , except: It doesn't have to be unique. One item can have multiple aliases . It's not RECOMMENDED to create an alias that has nothing to do with an item's ID . Usually an item 's alias is part of its ID so it's easy to recognize and memorize. For example, for the case above, we usually create an alias Format() . We can easily get a \"global\" alias for an item by replacing the ID part of its UID with its alias. 2. File Structure 2.1 File Format You can use any file format that can represent structural data to store metadata. However, we recommend using YAML or JSON . In this document, we use YAML in examples, but all YAML can be converted to JSON easily. 2.2 File Layout A metadata file consists of two parts: An \"item\" section and a \"reference\" section. Each section is a list of objects and each object is a key-value pair (hereafter referred to as \"property\") list that represents an item . 2.3 Item Section Though items can be hierarchical, they are flat in an item section. Instead, each item has a \"children\" property indicating its children and a \"parent\" property indicating its parent. An item object has some basic properties: Property Description uid REQUIRED . The unique identifier of the item . children OPTIONAL . A list of UIDs of the item 's children. Can be omitted if there are no children . parent OPTIONAL . The UID of the item 's parent. If omitted, metadata parser will try to figure out its parent from the children information of other items within the same file. Here is an example of a YAML format metadata file for C# Object class: items: - uid: System.Object parent: System children: - System.Object.Object() - System.Object.Equals(System.Object) - System.Object.Equals(System.Object,System.Object) - System.Object.Finalize() - System.Object.GetHashCode() - System.Object.GetType() - System.Object.MemberwiseClone() - System.Object.ReferenceEquals() - System.Object.ToString() - uid: System.Object.Object() parent: System.Object - uid: System.Object.Equals(System.Object) parent: System.Object - uid: System.Object.Equals(System.Object,System.Object) parent: System.Object - uid: System.Object.Finalize() parent: System.Object - uid: System.Object.GetHashCode() parent: System.Object - uid: System.Object.GetType() parent: System.Object - uid: System.Object.MemberwiseClone() parent: System.Object - uid: System.Object.ReferenceEquals() parent: System.Object - uid: System.Object.ToString() parent: System.Object references: ... Items SHOULD be organized based upon how they will display in documentation. For example, if you want all members of a class be displayed in a single page, put all members in a single metadata file. 2.3 Item Object In additional to the properties listed in last section, item object also has some OPTIONAL properties : Property Description id The identifier of the item . alias A list of aliases of the item . name The display name of the item . fullName The full display name of the item . In programming languages, it's usually the full qualified name. type The type of the item , such as class, method, etc. url If it's a relative URL, then it's another metadata file that defines the item . If it's an absolute URL, it means the item is coming from an external library, and the URL is the documentation page of this item . If omitted, the URL is the location of the current file. source The source code information of the item . It's an object that contains following properties : 1. repo: The remote Git repository of the source code. 2. branch: the branch of the source code. 3. revision: The Git revision of the source code. 4. path: the path to the source code file where the item is defined. 5. startLine: the start line of the item definition. 6. endLine: the end line of the item definition. Here is an example of a C# Dictionary class: - uid: System.Collections.Generic.Dictionary`2 id: Dictionary`2 alias: - Dictionary parent: System.Collections.Generic name: Dictionary<TKey, TValue> fullName: System.Collections.Generic.Dictionary<TKey, TValue> type: class url: System.Collections.Generic.Dictionary`2.yml source: repo: https://github.com/dotnet/netfx.git branch: master revision: 5ed47001acfb284a301260271f7d36d2bb014432 path: src/system/collections/generic/dictionary.cs startLine: 1 endLine: 100 2.4 Custom Properties Besides the predefined properties , item can have its own properties . One restriction is property name MUST NOT contains dots, as dot in property name will have special meaning (described in later section). 2.5 Reference Section Reference section also contains a list of items . These items serve as the references by items in item section and won't show up in documentation. Also, reference item doesn't need to have full properties , it just contains necessary information needed by its referrer (for example, name or URL). In metadata file, all items MUST be referenced by UID . It's RECOMMENDED to include all referenced items in reference section. This makes the file self-contained and easy to render at runtime. Many programming languages have the concept of \"template instantiation\". For example, in C#, you can create a new type List<int> from List<T> with argument int . You can create a reference for \"template instances\". For example, for a class inherited from List<int> : items: - uid: NumberList inherits: - System.Collections.Generic.List<System.Int32> references: - uid: System.Collections.Generic.List`1<System.Int32> link: @\"System.Collections.Generic.List`1\"<@\"System.Int32\"> - uid: System.Collections.Generic.List`1 name: List url: system.collections.generic.list`1.yml - uid: System.Int32 name: int url: system.int32.yml 2.6 Multiple Language Support An item may need to support multiple languages. For example, in .NET, a class can be used in C#, VB, managed C++ and F#. Different languages may have differences in properties . For example, a list of string is displayed as List<string> in C#, while List(Of string) in VB. To support this scenario, we introduce a concept of language context to allow defining different property values in different languages. If a property name is in the form of property_name.language_name , it defines the value of property_name under language_name . For example: - uid: System.Collections.Generic.Dictionary`2 name.csharp: Dictionary<TKey, TValue> name.vb: Dictionary(Of TKey, TValue) This means the name of dictionary is Dictionary<TKey, TValue> in C# and Dictionary(Of TKey, TValue) in VB. The following properties SHALL NOT be overridden in language context: uid, id, alias, children, and parent. 3. Work with Metadata in Markdown 3.1 YAML Metadata Section In a Markdown file, you can also define items using the same metadata syntax. The metadata definition MUST be in YAML format and enclosed by triple-dash lines ( --- ). Here is an example: --- uid: System.String summary: String class --- This is a **string** class. You can have multiple YAML sections inside a single Markdown file, but in a single YAML section, there MUST be only one item . The YAML metadata section does not have to contain all properties . The only property that MUST appear is \"uid\", which is used to match the same item in metadata file. The most common scenario for using YAML section is to specify which item the markdown doc belongs to. But you can also overwrite item property by defining one with the same name in YAML section. In the above example, the property \"summary\" will overwrite the same one in metadata. As with language context, the following properties SHALL NOT be overridden: uid, id, alias, children, and parent. You SHALL NOT define new item in Markdown. 3.2 Reference Items in Markdown To cross reference an item , you can use URI with xref scheme. You can either use standard link or automatic link with the above URI. For example, to cross reference System.String : [System.String](xref:System.String) <xref:System.String> Since item reference is a URI, special characters (like # , ? ) MUST be encoded . We also introduce a shorthand markdown syntax to cross reference easily: If a string starts with @ , and followed by a string enclosed by quotes ' or double quotes \" , it will be treated as an item reference. The string inside \"\" or '' is the UID of the item . Here is one example: @\"System.String\" Markdown processor MAY implement some algorithm to allow omit curly braces if ID is simple enough. For example, For reference like @\"int\" , we may also want to allow @int . When rendering references in Markdown, they will expand into a link with the item 's name as link title. You can also customize the link title using the standard syntax of Markdown: [Dictionary](xref:System.Collections.Generic.Dictionary`2)<[String](xref:System.String), [String](xref:System.String)> Will be rendered to: Dictionary < String , String > Besides UID , we also allow referencing items using ID and alias , in the Markdown processor, the below algorithm SHOULD be implemented to resolve references. Check whether the reference matches: Any identifier of current item 's children. Any alias of current item 's children. Any identifier of current item 's silbings. Any alias of current item 's silbings. A UID . A global alias ."
  },
  "tutorial/advanced_support_hyperlink.html": {
    "href": "tutorial/advanced_support_hyperlink.html",
    "title": "🔧 Advanced: Support Hyperlink | DocFX website",
    "keywords": "🔧 Advanced: Support Hyperlink In this topic, we will support hyperlinking in rtf files. Create a hyperlink in the rtf file: Open foo.rtf by Word . Add a hyperlink in content Set the link target to an existing bar.rtf Save the document. About link An author can write any valid hyperlink in the document, and then needs to run DocFX build to update file links. What is file link: The hyperlink must be a relative path and not rooted. valid: foo\\bar.rtf , ../foobar.rtf invalid: /foo.rtf , c:\\foo\\bar.rtf , http://foo.bar/ , mailto:foo@bar.foobar The file must exist. Why update file link: The story is: In foo.rtf , it has a file link to bar.rtf . In document build, bar.rtf generates a file with the name bar.html . But in foo.rtf , the link target is still bar.rtf , thus in the output folder we cannot find this file and we will get a broken link. To resolve the broken link, we need to update the link target from bar.rtf to bar.html . File link is a relative path, but we cannot track the relative path easily. So we track the normalized file path instead. What is a normalized file path : It always starts from the working folder (the folder that contains docfx.json ), and we write it as ~/ . No ../ or ./ or // Replace \\ with / . No url encoding. The path must be same as it in the file system. No anchor. Finally, a valid normalized file path looks like: ~/foo/bar.rtf . Pros Same form in different documents when the target is the same file. When file structure is: z:\\a\\b\\foo.rtf z:\\a\\b\\c\\bar.rtf z:\\a\\b\\c\\foobar.rtf Link target c/foobar.rtf in foo.rtf and link target foobar.rtf in bar.rtf is the same file. When the working folder is z:\\a\\ , the link target is always ~/b/c/foobar.rtf . Avoids differences in style when referring to the same file. For example, the following hyperlinks target the same file: a/foo.rtf , ./a/foo.rtf , a/b/../foo.rtf , a//foo.rtf , a\\foo.rtf Cons A folder with the name ~ is not supported. Prepare Open the rtf plug-in library project in Visual Studio . Add nuget packages: for plug-in: Microsoft.DocAsCode.Utility Add framework assembly reference: System.Core , System.Web , System.Xml.Linq Update rtf document processor Following the rules for hyperlink, add a FixLink help method: private static void FixLink(XAttribute link, RelativePath filePath, HashSet<string> linkToFiles) { string linkFile; string anchor = null; if (PathUtility.IsRelativePath(link.Value)) { var index = link.Value.IndexOf('#'); if (index == -1) { linkFile = link.Value; } else if (index == 0) { return; } else { linkFile = link.Value.Remove(index); anchor = link.Value.Substring(index); } var path = filePath + (RelativePath)linkFile; var file = (string)path.GetPathFromWorkingFolder(); link.Value = file + anchor; linkToFiles.Add(HttpUtility.UrlDecode(file)); } } RelativePath helps us generate the links correctly. Then add CollectLinksAndFixDocument method: private static HashSet<string> CollectLinksAndFixDocument(FileModel model) { string content = (string)((Dictionary<string, object>)model.Content)[\"conceptual\"]; var doc = XDocument.Parse(content); var links = from attr in doc.Descendants().Attributes() where \"href\".Equals(attr.Name.LocalName, StringComparison.OrdinalIgnoreCase) || \"src\".Equals(attr.Name.LocalName, StringComparison.OrdinalIgnoreCase) select attr; var path = (RelativePath)model.File; var linkToFiles = new HashSet<string>(); foreach (var link in links) { FixLink(link, path, linkToFiles); } using (var sw = new StringWriter()) { doc.Save(sw); ((Dictionary<string, object>)model.Content)[\"conceptual\"] = sw.ToString(); } return linkToFiles; } Modify Save method with report links: public SaveResult Save(FileModel model) { HashSet<string> linkToFiles = CollectLinksAndFixDocument(model); return new SaveResult { DocumentType = \"Conceptual\", ModelFile = model.File, LinkToFiles = linkToFiles.ToImmutableArray(), }; } <!-- todo : `Update Reference` is preserved for next version of plugin. --> View final RtfDocumentProcessor.cs Test and verify Build project. Copy dll to Plugins folder. Modify rtf file, create hyperlink, link to another rtf file, and save. Build with command DocFX build . Verify output html file."
  },
  "toc.html": {
    "href": "toc.html",
    "title": "Table of Content",
    "keywords": ""
  },
  "guideline/toc.html": {
    "href": "guideline/toc.html",
    "title": "Table of Content",
    "keywords": ""
  },
  "spec/toc.html": {
    "href": "spec/toc.html",
    "title": "Table of Content",
    "keywords": ""
  },
  "tutorial/toc.html": {
    "href": "tutorial/toc.html",
    "title": "Table of Content",
    "keywords": ""
  },
  "tutorial/intro_overwrite_files.html": {
    "href": "tutorial/intro_overwrite_files.html",
    "title": "Overwrite Files | DocFX website",
    "keywords": "Overwrite Files Introduction DocFX supports processing Markdown files, as well as structured data model in YAML or JSON format. We call Markdown files Conceptual File s, and the structured data model files Metadata File s. Current supported Metadata File s include: YAML files presenting managed reference model following Metadata Format for .NET Languages . Swagger JSON files presenting Swagger REST API model following Swagger Specification Version 2.0 . Inside DocFX, both Conceptual File s and Metadata File s are represented as Model s with different properties. Details on Model structure for these files are described in Data model inside DocFX section. DocFX introduces the concept of Overwrite File to modify or add properties to Model s without changing the input Conceptual File s and Metadata File s. The format of Overwrite File s Overwrite File s are Markdown files with multiple Overwrite Section s starting with YAML header block. A valid YAML header for an Overwrite Section MUST take the form of valid YAML set between triple-dashed lines and start with property uid . Here is a basic example of an Overwrite Section : --- uid: microsoft.com/docfx/Contacts some_property: value --- Further description for `microsoft.com/docfx/Contacts` Each Overwrite Section is transformed to Overwrite Model inside DocFX. For the above example, the Overwrite Model represented in YAML format is: uid: microsoft.com/docfx/Contacts some_property: value conceptual: <p><b>Content</b> in Markdown</p> Anchor *content *content is the keyword invented and used specifically in Overwrite File s to represent the Markdown content following YAML header. We leverage Anchors syntax in YAML specification for *content . The value for *content is always transformed from Markdown content to HTML. When *content is not used, the Markdown content below YAML header will be set to conceptual property; When *content is used, the Markdown content below YAML header will no longer be set to conceptual property. With *content , we can easily add Markdown content to any properties. --- uid: microsoft.com/docfx/Contacts footer: *content --- Footer for `microsoft.com/docfx/Contacts` In the above example, the value for *content is <p>Footer for <code>microsoft.com/docfx/Contacts</code></p> , and the Overwrite Model represented in YAML format is: uid: microsoft.com/docfx/Contacts footer: <p>Footer for <code>microsoft.com/docfx/Contacts</code></p> uid for an Overwrite Model stands for the Unique IDentifier of the Model it will overwrite. So it is allowed to have multiple Overwrite Section s with YAML Header containing the same uid . For one Overwrite File , the latter Overwrite Section overwrites the former one with the same uid . For different Overwrite File s, the order of overwrite is Undetermined . So it is suggested to have Overwrite Sections with the same uid in the same Overwrite File . When processing Conceptual File s and Metadata File s, Overwrite Model s with the same uid are applied to the processed Model s. Different Model s have different overwrite principles, Overwrite principles section describes the them in detail. Apply Overwrite File s Inside docfx.json , overwrite is used to specify the Overwrite File s. Overwrite principles As a general principle, uid is always the key that an Overwrite Model find the Model it is going to overwrite. So a Model with no uid defined will never get overwritten. Different types of files produce different Model s. The quickest way to get an idea of what the Model looks like is to run: docfx build --exportRawModel --exportRawModel exports Model in JSON format with .raw.json extension. The basic principle of Overwrite Model is: It keeps the same data structure as the Model it is going to overwrite If the property is defined in Model , please refer Data model inside DocFX for the specific overwrite behavior for a specific property. If the property is not defined in Model , it is added to Model Data model inside DocFX Managed reference model Key Type Overwrite behavior uid uid Merge key. assemblies string[] Ignore. attributes Attribute [] Ignore. children uid[] Ignore. documentation Source Merge. example string[] Replace. exceptions Cref [] Merge keyed list. fullName string Replace. fullName. string Replace. id string Replace. implements uid[] Ignore. inheritance uid[] Ignore. inheritedMembers uid[] Ignore. isEii boolean Replace. isExtensionMethod boolean Replace. langs string[] Replace. modifiers. string[] Ignore. name string Replace. name. string Replace. namespace uid Replace. overridden uid Replace. parent uid Replace. platform string[] Replace. remarks markdown Replace. see Cref [] Merge keyed list. seealso Cref [] Merge keyed list. source Source Merge. syntax Syntax Merge. summary markdown Replace. type string Replace. Source Property Type Overwrite behavior base string Replace. content string Replace. endLine integer Replace. id string Replace. isExternal boolean Replace. href string Replace. path string Replace. remote GitSource Merge. startLine integer Replace. GitSource Property Type Overwrite behavior path string Replace. branch string Replace. repo url Replace. commit Commit Merge. key string Replace. Commit Property Type Overwrite behavior committer User Replace. author User Replace. id string Replace. message string Replace. User Property Type Overwrite behavior name string Replace. email string Replace. date datetime Replace. Cref Property Type Overwrite behavior type uid Merge key. description markdown Replace. commentId string Replace. Syntax Property Type Overwrite behavior content string Replace. content. string Replace. parameters Parameter [] Merge keyed list. typeParameters Parameter [] Merge keyed list. return Parameter Merge. Parameter Property Type Overwrite behavior id string Merge key. description markdown Replace. attributes Attribute [] Ignore. type uid Replace. Attribute Property Type Overwrite behavior arguments Argument [] Ignore. ctor uid Ignore. namedArguments NamedArgument [] Ignore. type uid Ignore. Argument Property Type Overwrite behavior type uid Ignore. value object Ignore. NamedArgument Property Type Overwrite behavior name string Ignore. type string Ignore. value object Ignore. REST API model Key Type Overwrite behavior children REST API item model Overwrite when uid of the item model matches summary string Overwrite description string Overwrite REST API item model Key Type Overwrite behavior uid string Key Conceptual model Key Type Overwrite behavior title string Overwrite rawTitle string Overwrite conceptual string Overwrite"
  },
  "tutorial/intro_rest_api_documentation.html": {
    "href": "tutorial/intro_rest_api_documentation.html",
    "title": "Introduction to REST API Documentation | DocFX website",
    "keywords": "Introduction to REST API Documentation Introduction DocFX now supports generating documentation from REST APIs following Swagger specification version 2.0. The Swagger RESTful API files MUST end with .json . One Swagger API file generates one HTML file. For example. a file contacts.swagger.json generates file naming contacts.html . Basic structure A single Swagger API file is considered as a unique REST File containing multiple API s. The UID (Unique IDentifier) for the File is defined as the combination of host , basePath , info.title and info.version with / as separator. For example, the following Swagger API file has UID equals to microsoft.com/docfx/Contacts/1.6 : { \"swagger\": \"2.0\", \"info\": { \"title\": \"Contacts\", \"version\": \"1.6\" }, \"host\": \"microsoft.com\", \"basePath\": \"/docfx\", \"schemes\": [ \"https\" ] } A REST API File contains multiple API s as its children. An API is an Operation Object defined in Path Item Object . The UID (Unique IDentifier) for this API is defined as the combination of the UID of the File and the operationId of the Operation Object . For example, the following get_contacts operation has UID equal to microsoft.com/docfx/Contacts/1.6/get_contacts : { \"swagger\": \"2.0\", \"info\": { \"title\": \"Contacts\", \"version\": \"1.6\" }, \"host\": \"microsoft.com\", \"basePath\": \"/docfx\", \"schemes\": [ \"https\" ], \"paths\": { \"/contacts\": { \"get\": { \"parameters\": [ ], \"responses\": { }, \"operationId\": \"get_contacts\" } } } } It is recommended that user provides a well-formed operationId name. We suggest that the operationId is one word in camelCase or snake_case. A REST API File could also contain multiple tags. The tag is a Tag Object , which is optional and used by Operation Object . The UID (Unique IDentifier) for this tag is defined as the combination of UID of the File , tag , and name of the Tag Object . For example, the following tag Basic has UID microsoft.com/docfx/Contacts/1.6/tag/Basic : { \"swagger\": \"2.0\", \"info\": { \"title\": \"Contacts\", \"version\": \"1.6\" }, \"host\": \"microsoft.com\", \"basePath\": \"/docfx\", \"schemes\": [ \"https\" ], \"tags\": [ { \"name\": \"Basic\", \"description\": \"Basic description\" }, { \"name\": \"Advanced\", \"description\": \"Advanced description\" } ] } HTML layout The generated HTML file lists all the API s inside the File in the order defined in the Swagger REST file. You can use Overwrite File s to add more information to the File and API , and use tags to organize the sections of the API s. Overwrite File s Overwrite File s are Markdown files with multiple Overwrite Section s starting with YAML header block. A valid YAML header for an Overwrite Section MUST take the form of valid YAML set between triple-dashed lines and start with property uid . Here is a basic example of an Overwrite Section : --- uid: microsoft.com/docfx/Contacts/1.6 --- Further description for `microsoft.com/docfx/Contacts/1.6` The uid value MUST match the uid of the File or API that you want to overwrite. The content following YAML header is the additional Markdown description for the File or API . By default, it is transformed to HTML and appended below the description of the File or API . Add footer You can also define the footer of an File or API using the following syntax: --- uid: microsoft.com/docfx/Contacts/1.6 footer: *content --- Footer for `microsoft.com/docfx/Contacts/1.6` *content is the keyword representing the Markdown content following YAML header. The value for *content is always transformed from Markdown content to HTML. In the above example, the value for *content is <p>Footer for <code>microsoft.com/docfx/Contacts/1.6</code></p> . In this way, the value of footer for API microsoft.com/docfx/Contacts/1.6 is set to <p>Footer for <code>microsoft.com/docfx/Contacts/1.6</code></p> . We leverage Anchors syntax in YAML specification for *content . If footer is set, the content from footer will be appended to the last section of the File or API . It is usually used to define See Also or Additional Resources for the documentation. Tags to organize the sections of APIs You can organize the sections of APIs by using tags in Swagger file, following definitions in Tag Object . Each API can be specified with one or multiple tags, or not speficied with any tag. If all APIs are not tagged, each API will not be included in any sections. If the API is specified with one tag only, it will show inside this one tag section. If the API is specified with multiple tags, it will show inside multiple tag sections. If some APIs are specified with tags while some other APIs are not, the untagged APIs will be organized into one auto generated Other apis section. Specific bookmark could be added to tag section using x-bookmark-id , which is Swagger schema extensions following Specification Extensions . If no x-bookmark-id is specified, name of the tag will be the default bookmark. For example, the following swagger file defines Basic and Advanced tags. Sections in the layout: set_contacts API is tagged with Advanced only, then it will only show inside Advanced tag section. get_contacts API is tagged with both Basic and Advanced , then it will show inside both of the tag sections. delete_contacts API is not tagged, it will show inside \"Other apis\" section. Bookmarks: Bookmark of Basic tag is BasicBookmark , which is defined by x-bookmark-id . Bookmark of Advanced tag is Advanced , which use name by default. { \"swagger\": \"2.0\", \"info\": { \"title\": \"Contacts\", \"version\": \"1.6\" }, \"host\": \"microsoft.com\", \"basePath\": \"/docfx\", \"schemes\": [ \"https\" ], \"tags\": [ { \"name\": \"Basic\", \"x-bookmark-id\": \"BasicBookmark\", \"description\": \"Basic description\" }, { \"name\": \"Advanced\", \"description\": \"Advanced description\" } ], \"paths\": { \"/contacts\": { \"get\": { \"operationId\": \"get_contacts\", \"tags\": [ \"Basic\", \"Advanced\" ] }, \"set\": { \"operationId\": \"set_contacts\", \"tags\": [ \"Advanced\" ] }, \"delete\": { \"operationId\": \"delete_contacts\" } } } } For the example above, the simple html layout will be: <h2 id=\"BasicBookmark\">Basic</h2> <h3 data-uid=\"microsoft.com/docfx/Contacts/1.6/get_contacts\">get_contacts</h3> <h2 id=\"Advanced\">Advanced</h2> <h3 data-uid=\"microsoft.com/docfx/Contacts/1.6/get_contacts\">get_contacts</h3> <h3 data-uid=\"microsoft.com/docfx/Contacts/1.6/set_contacts\">set_contacts</h3> <h2 id=\"other-apis\">Other APIs</h2> <h3 data-uid=\"microsoft.com/docfx/Contacts/1.6/delete_contacts\">delete_contacts</h3> Overwrite the tags More information could be added to the tag as following: --- uid: microsoft.com/docfx/Contacts/1.6/tag/Basic --- Additional comments for `microsoft.com/docfx/Contacts/1.6/tag/Basic` The description of the tag could be overwritten as following: --- uid: microsoft.com/docfx/Contacts/1.6/tag/Basic description: *content --- Overwrite description for `microsoft.com/docfx/Contacts/1.6/tag/Basic` Add other metadata You can define your own metadata with YAML header. This functionality is quite useful when your own template is used. When the key of the metadata is already preserved by DocFX, for example, summary , the value of summary will be overwritten. You can also overwrite complex types, for example, description of a parameter . Make sure the data structure of the provided metadata is consistent with the one defined in DocFX, otherwise, DocFX is unable to cast the value and fails. When the key of the metadata is not preserved by DocFX, for example, not_predefined . The metadata is kept and can be used in the template."
  },
  "tutorial/intro_template.html": {
    "href": "tutorial/intro_template.html",
    "title": "Introduction to DocFX Template System | DocFX website",
    "keywords": "Introduction to DocFX Template System DocFX Template System provides a flexible way of defining and using templates. As the following DocFX workflow shows, DocFX loads the set of files and transforms them into different data models using different types of Document Processor s. Afterwards, DocFX Template System loads these data models, and transforms them into output files based on the document type of the data model. Each file belongs to a document type . For example, the document type for Markdown files is conceptual , and the document type for toc.md files is Toc . For a specific Template , each document type can have several Renderer s. For a specific file, DocFX Template System picks the corresponding Renderer s to render the input data model into output files. Renderer Renderer s are files written in a specific templating language. It is used to transform the input data model into output files. Currently DocFX supports the following templating languages: Mustache templating language Liquid templating language Naming rule for a Renderer file The naming rule for a Renderer file is: <document_type>.<output_extension>[.primary].<template_extension> . <document_type> is the document type current Renderer responsible to. <output_extension> defines the extension of the output files going through current Renderer . For example, conceputal.html.tmpl transforms file1.md into output file file1.html , and toc.json.tmpl transforms toc.md into output file toc.json . [.primary] is optional. It is used when there are multiple Renderer s with different extension for one particular document type. The output file transformed by the .primary Renderer is used as the file to be linked. The below example describes the behavior in detail. <template_extension> is the extension of the Renderer file based on the templating language it uses. For Mustache Renderer , it is .tmpl , while for Liquid Renderer , it is .liquid . Here is an example. The following template contains two Mustache Renderer files for conceptual document type: /- some_template/ |- conceptual.html.primary.tmpl \\- concetpual.mta.json.tmpl There are two Markdown files A.md and B.md , the content for A.md is: [Link To B](B.md) DocFX Template System produces two output files for A.md : A.html and A.mta.json , and also two output files for B.md : B.html and B.mta.json . According to conceptual.html.primary.tmpl , .html is the primary output file, the link from A.md to B.md is resolved to B.html instead of B.mta.json , which is to say, the content of A.md is transformed to: <a href=\"B.html\">Link To B</a> If no primary Renderer is defined, DocFX randomly picks one Renderer as the primary one, and the result is unpredictable. Renderer in Mustache syntax Introduction to Mustache Mustache is a logic-less template syntax containing only tag s. It works by expanding tags in a template using values provided in a hash or object. Tag s are indicated by the double mustaches. {{name}} is a tag, it tries to find the name key in current context, and replace it with the value of name . mustache.5 lists the syntax of Mustache in detail. Naming rule Renderer s in Mustache syntax MUST end with .tmpl extension. Mustache Partials Mustache Partials is also supported in DocFX Template System . Partials are common sections of Renderer that can be shared by multiple Renderer files. Partials MUST end with .tmpl.partial . For example, inside a Template , there is a Partial file part.tmpl.partial with content: Inside Partial {{ name }} To reuse this Partial file, Renderer file uses the following syntax: Inside Renderer {{ >part }} It has the same effect with the following Renderer file: Inside Renderer Inside Partial {{ name }} Extended syntax for Dependencies When rendering the input data model into output files, for example, html files, the html file may rely on other files to display correctly. For example, the html file dependents on stylesheet file main.css . We call such file main.css a Dependency to the Renderer . DocFX introduces the following syntax to define the dependency for the Renderer : {{!include('<file_name>')}} docfx copies these dependencies to output folder preserving its relative path to the Renderer file. Tips: Mustache is logic-less, and for a specific {{name}} tag, Mustache searches its context and its parent context recursively. So most of the time Preprocessor File is used to re-define the data model used by the Mustache Renderer . Renderer in Liquid syntax Naming rule Renderer s in Liquid syntax MUST end with .liquid extension. Liquid contains include tag to support partials, we follow the ruby partials naming convention to have _<partialName>.liquid as partial template. Extended syntax for Dependencies DocFX introduces a custom tag ref , e.g. {% ref file1 %} , to specify the resource files that current template depends on. Preprocessor Renderer s take the input data model produced by document processor and render them into output files. Sometimes the input data model is not exactly what Renderer s want. DocFX Template System introduces the concept of Preprocessor to transform the input data model into what Renderer s exactly want. We call the data model Preprocessor returns the View Model . View Model is the data model to apply Renderer . Naming rule for Preprocessor The naming of Preprocessor follows the naming of Renderer with file extension changes to .js : <renderer_file_name_without_extension>.js . If a Preprocessor has no corresponding Renderer however it still needs to be executed, for example, to run exports.getOptions function , it should be named as <document_type>.tmpl.js . Syntax for Preprocessor Preprocessor s are JavaScript files following ECMAScript 5.1 standard. DocFX Template System uses Jint as JavaScript Engine, and provides several additional functions for easy debugging and integration. Module Preprocessor leverages the concept of Module as similar to the Module in Node.js . The syntax of Module in Preprocessor is a subset of the one in Node.js. The advantage of the Module concept is that the Preprocessor script file can also be run in Node.js. The Module syntax in Preprocessor is simple, To export function property from one Module file common.js : exports.util = function () {} To use the exported function property inside common.js : var common = require('./common.js'); // call util common.util(); Only relative path starting with ./ is supported. Log You can call the following functions to log messages with different error level: console.log , console.warn or console.warning and console.err . Function Signature A Preprocessor file is also considered as a Module. It MUST export the function property with the signature required by docfx 's prescriptive interop pattern. There are two functions defined. Function 1: exports.getOptions Function property getOptions takes the data model produced by document processor as the input argument, and the return value must be an object with the following properties: Property Name Type Description isShared bool Defines whether the input data model can be accessed by other data models when transform . By default the value is false . If it is set to true , the data model will be stored into Globally Shared Properties . A sample exports.getOptions defined in toc.tmpl.js is: exports.getOptions = function (model) { return { isShared: true; }; } <!-- TODO: add bookmarks part when it is implemented --> Function 2: exports.transform Function property transform takes the data model produced by document processor (described in further detail in The Input Data Model ) as the input argument, and returns the View Model . View Model is the exact model to apply the corresponding Renderer . A sample exports.transform for conceptual.txt.js is: exports.transform = function (model) { model._title = \"Hello World\" return model; } If conceptual.txt.tmpl is: {{{_title}}} Then Markdown file A.md is transformed to A.txt with content: Hello World Tip: For each file, the input data model can be exported to a JSON file by calling docfx build --exportRawModel . And the returned View Model can be exported to a JSON file by calling docfx build --exportViewModel . The Input Data Model The input data model used by transform not only contains properties extracted from the content of the file, but also system generated properties and globally shared properties. System Generated Properties System generated property names start with underscore _ , as listed in the following table: Name Description _rel The relative path of the root output folder from current output file. For example, if the output file is a/b/c.html from root output folder, then the value is ../../ . _path The path of current output file starting from root output folder. _navPath The relative path of the root TOC file from root output folder, if exists. The root TOC file stands for the TOC file in root output folder. For example, if the output file is html file, the value is toc.html . _navRel The relative path from current output file to the root TOC file, if exists. For example, if the root TOC file is toc.html from root output folder, the value is empty. _navKey The original file path of the root TOC file starting with ~/ . ~/ stands for the folder where docfx.json is in, for example, ~/toc.md . _tocPath The relative path of the TOC file that current output file belongs to from root output folder, if current output file is in that TOC file. If current output file is not defined in any TOC file, the nearest TOC file is picked. _tocRel The relative path from current output file to its TOC file. For example, if the TOC file is a/toc.html from root output folder, the value is ../ . _tocKey The original file path of the TOC file starting with ~/ . ~/ stands for the folder where docfx.json is in, for example, ~/a/toc.yml . Users can also override system generated properties by using YAML Header , fileMetadata or globalMetadata . Globally Shared Properties Globally shared properties are stored in __global key for every data model. Its initial value is read from global.json inside the Template if the file exists. If a data model has isShared equal to true with the above getOptions function property, it is stored in __global._shared with the original path starting with ~/ as the key."
  },
  "tutorial/intro_toc.html": {
    "href": "tutorial/intro_toc.html",
    "title": "Table-Of-Content (TOC) Files | DocFX website",
    "keywords": "Table-Of-Content (TOC) Files Introduction DocFX supports processing Markdown files, which we call Conceptual File s, as well as structured data model in YAML or JSON format, which we call Metadata File s. Besides that, DocFX introduces a way to organize these files using Table-Of-Content File s, which we also call TOC File s, so that users can navigate through Metadata File s and Conceptual File s. TOC File s must have file name toc.md or toc.yml , notice that file name is case-insensitive. Basic format Markdown format TOC toc.md toc.md leverages Markdown Atx-style headers which use 1-6 hash characters at the start of the line to represent the TOC levels 1-6. We call each line starting with hash characters a TOC Item . A TOC Item with higher level is considered as the child of the nearest upper TOC Item with less level. A sample toc.md is as below: # [Header1](href) ## [Header1.1](href) # Header2 ## [Header2.1](href) ### [Header2.1.1](href) ## [Header2.2](href) # @UidForAnArticle For a TOC Item , it can be either plain text, or a Markdown inline link , or @uid as the shortcut for cross-referenced Three kinds of links are supported: Absolute path, for example, http://example.net . Relative path, for example, ../example.md . This kind of link has several advanced usages and is described in detail below . URI with xref scheme, for example, xref:System.String , the value is the uid of the file to be cross-referenced . YAML format TOC toc.yml - name: Topic1 href: Topic1.md - name: Topic2 href: Topic2.md items: - name: Topic2_1 href: Topic2_1.md Comparing to toc.md , toc.yml represents a structured data model and conforms to the YAML standard . It supports advanced functionalities. Data model for toc.yml The data model for toc.yml is an array of TOC Item Object s. TOC Item Object TOC Item Object represents the data model for each TOC Item . Note that all the property names are case sensitive . Property Name Type Description name string Specifies the title of the TOC Item . href string Specifies the hyperlink of the TOC Item . items TOC Item Object Specifies the children TOC Items of current TOC Item . Advanced : These properties are useful when a TOC links another TOC, or links to a uid. Property Name Type Description tocHref string Specifies another TOC file, whose items are considered as the child of the currrent TOC Item . topicHref string Specifies the topic href of the TOC Item . It is useful when href is linking to a folder or tocHref is used. topicUid string Specifies the uid of the topicHref file. If the value is set, it overwrites the value of topicHref . homepage Deprecated string Specifies the homepage of the TOC Item . It is useful when href is linking to a folder. Use topicHref instead. uid Deprecated string Specifies the uid of the referenced file. If the value is set, it overwrites the value of href . Use topicUid instead. homepageUid Deprecated string Specifies the uid of the homepage. If the value is set, it overwrites the value of homepage . Use topicUid instead. Href in detail If a TOC Item is linking to some relative path, there are three cases: Linking to another TOC File , for example, href: examples/toc.md . Linking to a folder, which means, the value of the link ends with / explicitly, for example, href: examples/ Linking to some local file. Each case is described in detail below. Link to another TOC File If the TOC Item is linking to some other TOC File , it is considered as a placeholder of the referenced TOC File , and DocFX will extract content from that TOC File and insert into current TOC Item recursively . This technique is always used when you want to combine several TOC File s into one single TOC File . If homepage or topicHref is set for this TOC Item , it will be considered as the href of the expanded TOC Item . For example, one toc.yml file is like below: - name: How-to tutorials tocHref: howto/toc.yml topicHref: howto/overview.md It references to the toc.yml file under folder howto , with the following content: - name: \"How-to1\" href: howto1.md - name: \"How-to2\" href: howto2.md DocFX processes these toc.yml files and expands the uppder toc.yml file into: - name: How-to tutorials href: howto/overview.md topicHref: howto/overview.md items: - name: \"How-to1\" href: howto/howto1.md topichref: howto/howto1.md - name: \"How-to2\" href: howto/howto2.md topichref: howto/howto2.md NOTE that the referenced toc.yml file under howto folder will not be transformed to the output folder even if it is included in docfx.json . Link to a folder If the Toc Item is linking to a folder, ending with / explicitly, the link value for the Toc Item is determined in the following steps: If homepage topicHref or homepageUid topicUid is set, the link value is resolved to the relative path to homepage topicHref If homepage topicHref or homepageUid topicUid is not set, DocFX searches for Toc File under the folder, and get the first relative link to local file as the link value for current Toc Item . For example, if the Toc Item is href: article/ , and the content of article/toc.yml is as follows: - name: Topic1 href: topic1.md The link value for the Toc Item is resolved to article/topic1.md . If there is no Toc File under the folder, the link value keeps unchanged. Link to local file If the Toc Item is linking to a local file, we call this local file In-Toc File . Make sure the file is included in docfx.json . Not-In-Toc Files When a local file is not referenced by any Toc Item , we call this local file Not-In-Toc File . Its TOC File is the nearest TOC File in output folder from the same folder as the local file to the root output folder."
  },
  "tutorial/links_and_cross_references.html": {
    "href": "tutorial/links_and_cross_references.html",
    "title": "Links and Cross References | DocFX website",
    "keywords": "Links and Cross References Markdown provides a syntax to create hyperlinks. For example, the following syntax: [bing](http://www.bing.com) Will render to: <a href=\"http://www.bing.com\">bing</a> Here the url in the link could be either absolute url pointing to another website ( www.bing.com in the above example), or a relative url pointing to a local resource on the same server (for example, about.html ). When working with large documentation project that contains multiple files, it is often needed to link to another Markdown file using the relative path in the source directory. Markdown spec doesn't have a clear definition of how this should be supported. What's more, there is also a common need to link to another file using a \"semantic\" name instead of its file path. This is especially common in API reference docs, for example, you may want to use System.String to link to the topic of String class, without knowing it's actually located in api/system/string.html , which is auto generated. In this document, you'll learn the functionalities DocFX provides for resolving file links and cross reference, which will help you to reference other files in an efficient way. Link to a file using relative path In DocFX, you can link to a file using its relative path in the source directory. For example, You have a file1.md under root and a file2.md under subfolder/ : / |- subfolder/ | \\- file2.md \\- file1.md You can use relative path to reference file2.md in file1.md : [file2](subfolder/file2.md) DocFX converts it to a relative path in output folder structure: <a href=\"subfolder/file2.html\">file2</a> You can see the source file name ( .md ) is replaced with output file name ( .html ). DocFX does not simply replace the file extension here ( .md to .html ), it also tracks the mapping between input and output files to make sure source file path will resolve to correct output path. For example, if in the above case, subfolder is renamed to subfolder2 using file mapping in docfx.json , in output html, the link url will also resolve to subfolder2/file2.html . Relative path vs. absolute path It's recommended to always use relative path to reference another file in the same project. Relative path will be resolved during build and produce build warning if the target file does not exist. Tip: File must be included in docfx.json to be processed by DocFX, so if you see a build warning about broken link but the file actually exists in your file system, go and check whether this file is included in docfx.json . You can also use absolute path (path starts with / ) to link to another file, but DocFX won't check its correctness for you and will keep it as-is in the output HTML. That means you should use the output file path as absolute path. For example, in the above case, you can also write the link as follows: [file2](/subfolder/file2.html) Sometimes you may find it's complicated to calculate relative path between two files. DocFX also supports path starts with ~ to represent path relative to the root directory of your project (i.e. where docfx.json is located). This kind of path will also be validated and resolved during build. For example, in the above case, you can write the following links in file2.md : [file1](~/file1.md) [file1](../file1.md) Both will resolve to ../file1.html in output html. Automatic link doesn't support relative path. If you write something like <file.md> , it will be treated as an HTML tag rather than a link. Links in file includes If you use file include to include another file, the links in included file is relative to the included file. For example, if file1.md includes file2.md : [!include[file2](subfolder/file2.md)] All links in file2.md are relative to the file2.md itself, even when it's included by file1.md . Please note that the file path in include syntax is handled differently than Markdown link. You can only use relative path to specify location of the included file. And DocFX doesn't require included file to be included in docfx.json . Each file in docfx.json will build into an output file. But included files usually don't need to build into individual topics. So it's not recommended to include them in docfx.json . Links in inline HTML Markdown supports inline HTML . DocFX also supports to use relative path in inline HTML. Path in HTML link ( <a> ), image ( <img> ), script ( <script> ) and css ( <link> ) will also be resolved if they're relative path. Using cross reference Besides using file path to link to another file, DocFX also allows you to give a file a unique identifier so that you can reference this file using that identifier instead of its file path. This is useful in the following cases: Path to file is long and difficult to memorize or changes frequently. API reference documentation is usually auto generated so it's difficult to find its file path. You want to reference to files in another project without need to know its file structure. The basic syntax for cross referencing a file is: <xref:id_of_another_file> This is similar to automatic link syntax in Markdown but with a xref scheme. This link will build into: <a href=\"path_of_another_file\">title_of_another_file</a> As you can see, one benefit of using cross reference is that you don't need to specify the link text and DocFX will automatically resolve it for you. Title is extracted from the first heading of the Markdown file. Or you can also specify title using title metadata. Define UID The unique identifier of a file is called UID (stands for unique identifier) in DocFX. For Markdown file, you can specify its UID by adding a UID metadata in YAML header . For example, the following Markdown defined a UID \"fileA\". --- uid: fileA --- # This is fileA ... UID is supposed to be unique inside a project. If you define duplicate UID for two files, the resolve result is undetermined. For API reference files, UID is auto generated by mangling API's signature. For example, System.String class's UID is System.String . You can open the generated YAML files to lookup the value of UID. Conceptual Markdown file doesn't have UID generated by default. So it cannot be cross referenced unless you give it a UID. Different syntax of cross reference Besides the auto link, we also support some other ways to use cross references: Markdown link In Markdown link, you can also use xref in link url: [link_text](xref:uid_of_another_file) This will resolve to: <a href=\"path_of_another_file\">link_text</a> In this case, we won't resolve the link text for you because you already specified it, unless the link_text is empty. Shorthand form You can also use @uid_to_another_file to quickly reference another file. There are some rules for DocFX to determine whether a string following @ are UID: The string after @ must start with [A-Za-z] , and end with: Whitespace or line end Punctuation ( [.,;:!?`~] ) followed by whitespace or line end Two or more punctuations ( [.,;:!?`~] ) A string enclosed by a pair of quotes ( ' or \" ) The render result of @ form is same as auto link form. For example, @System.String is same as <xref:System.String> . Using hashtag in cross reference Sometimes you need to link to the middle of a file (an anchor) rather than jump to the beginning of a file. DocFX also allows you to do that. In Markdown link or auto link, you can add a hashtag ( # ) followed by the anchor name after UID. For example: <xref:uid_to_file#anchor_name> [link_text](xref:uid_to_file#anchor_name] Both urls will resolve to url_to_file#anchor_name in output HTML. The link text still resolves to the title of the whole file. If it's not what you need, you can specify your own link text. Hashtag in xref is always treated as separator between file name and anchor name. That means if you have # in UID, it has to be encoded to %23 . Hashtag is not supported in @ form. Link to overwrite files Overwrite file itself doesn't build into individual output file. It's merged with the API reference item model to build into a single file. If you want to link to the content inside an overwrite file (for example, an anchor), you cannot use the path to the overwrite file. Instead, you should either cross reference its UID, or link to the YAML file that contains the API. For example, you have String class which is generated from system.string.yml , then you have a string.md that overwrites its conceptual part which contains a compare-strings section. You can use one of the following syntax to link to this section: [compare strings](xref:System.String#compare-strings) [compare strings](system.string.yml#compare-strings) Both will render to: <a href=\"system.string.html#compare-strings\">compare strings</a> Cross reference between projects Another common need is to reference topics from an external project. For example, when you're writing the documentation for your own .NET library, you'll want to add some links that point to types in .NET base class library. DocFX gives you this functionality by exporting all UIDs in a project into a map file and you can import it in another project to use them. Cross reference map file When building a DocFX project, there will be an xrefmap.yml generated under output folder. This file contains information for all topics that have UID defined and their corresponding urls. The format of xrefmap.yml looks like this: references: - uid: uid_of_topic name: title_of_topic href: url_of_topic.html fullName: full_title_of_topic - ... It's a YAML object that contains following properties: references : a list of topic information, each item contains following properties: uid : UID to a conceptual topic or API reference name : title of the topic href : url to the topic, which is an absolute url or relative path to current file ( xrefmap.yml ) fullName : doesn't apply to conceptual, means the fully qualified name of API. For example, for String class, its name is String and fully qualified name is System.String . This property is not used in link title resolve for now but reserved for future use. Topic is not necessarily to be a file, it can also be a section inside a file. For example, a method in a class. In this case its url could be an anchor in a file. Using cross reference map You can import a cross reference map file in your DocFX then all UIDs defined that file can be cross referenced. To use a cross reference map, add a xrefMaps config to build section of docfx.json : { \"build\": { \"xrefMaps\": [ \"<path_to_xrefmap>\" ], ... } } The value of xrefMaps could be a string or a list of strings that contain the path/url to cross reference maps. DocFX supports reading cross reference map from a local file or a web location. It's recommended to deploy xrefmap.yml to the website together with topic files so that others can directly use its url in docfx.json instead of downloading it to local. Then you can use any cross reference syntax in your Markdown file, DocFX will be able to resolve it to the right target url. Cross reference .NET BCL types When creating documentation for your own .NET library, it is needed to link to the types in .NET base class library. The .NET Framework reference documentation is not generated by DocFX, so we created a cross reference map for you so that you can use it in your project to reference .NET BCL types. This can be downloaded on nuget . You can also manually create xrefmap.yml for project that is not generated by DocFX to be able to cross reference topics in it."
  },
  "tutorial/validate_your_markdown_files.html": {
    "href": "tutorial/validate_your_markdown_files.html",
    "title": "Validate Your Markdown Files | DocFX website",
    "keywords": "Validate Your Markdown Files In Markdown, we can write any document with valid syntax. For example, Markdown supports to directly write HTML tag, we can write HTML tag <h1>title</h1> instead of Markdown syntax #title . But for some purpose, some behaviors are unwanted, for example, you may not want to allow <script> tag in Markdown that can insert any javascript. In this document, you'll learn how to define markdown validation rules, which will help you to validate markdown documents in an efficient way. Markdown validation is part of DFM, if you switch Markdown engine to other engine, validation might not work. There're three kinds of validation rules provided by DocFX: HTML tag rule, which is used to validate HTML tags in Markdown. There is a common need to restrict usage of HTML tags in Markdown to only allow \"safe\" HTML tags, so we created this built-in rule for you. Markdown token rule. This can be used to validate different kinds of Markdown syntax elements, like headings, links, images, etc. Metadata rule. This can be used to validate metadata of documents. Metadata can be defined in YAML header, docfx.json , or a single JSON file. Metadata rule gives you a central place to validate metadata against certain principle. HTML tag validation rules For most cases, you may want to prohibit using certain html tags in markdown, so we built a built-in html tag rule for you. To define a HTML tag rule, simply create a md.style with following content: { \"tagRules\": [ { \"tagNames\": [ \"H1\", \"H2\" ], \"relation\": \"In\", \"behavior\": \"Warning\", \"messageFormatter\": \"Please do not use <H1> and <H2>, use '#' and '##' instead.\", \"customValidatorContractName\": null, \"openingTagOnly\": false } ] } Then when anyone write <H1> or <H2> in Markdown file, it will give a warning. You can use the following proprties to configure the HTML tag rule: tagNames is the list of HTML tag names to validate, required , case-insensitive . relation is optional for tagNames : In means when html tag is in tagNames , this is default value. NotIn means when html tag is not in tagNames . behavior defines the behavior when the HTML tag is met, required . Its value can be following: None: Do nothing. Warning: Log a warning. Error: Log an error, it will break current build. messageFormatter is the log message when the HTML tag is hit, required . It can contain following variables: {0} the name of tag. {1} the whole tag. For example, the messageFormatter is {0} is the tag name of {1}. , and the tag is <H1 class=\"heading\"> match the rule, then it will output following message: H1 is the tag name of <H1 class=\"heading\">. customValidatorContractName is an extension tag rule contract name for complex validation rule, optional . see How to create a custom html tag validator . openingTagOnly is a boolean, option , default is false if true , it will only apply to opening tag, e.g. <H1> , otherwise, it will also apply to closing tag, e.g. </H1> . Test your rule To enable your rule, put md.style in the same folder of docfx.json , then run docfx , warning will be shown if it encounters <H1> or <H2> during build. Create a custom HTML tag rule By default HTML tag rule only validates whether an HTML tag exists in Markdown. Sometimes you may want to have additional validation against the content of the tag. For example, you may not want a tag to contain onclick attribute as it can inject javascript to the page. You can create a custom HTML tag rule to achieve this. Create a project in your code editor (e.g. Visual Studio). Add nuget package Microsoft.DocAsCode.Plugins and Microsoft.Composition . Create a class and implement @Microsoft.DocAsCode.Plugins.ICustomMarkdownTagValidator. Add ExportAttribute with contract name. For example, we require HTML link ( <a> ) should not contain onclick attribute: [Export(\"should_not_contain_onclick\", typeof(ICustomMarkdownTagValidator))] public class MyMarkdownTagValidator : ICustomMarkdownTagValidator { public bool Validate(string tag) { // use Contains for demo purpose, a complete implementation should parse the HTML tag. return tag.Contains(\"onclick\"); } } And update your md.style with following content: { \"tagRules\": [ { \"tagNames\": [ \"a\" ], \"behavior\": \"Warning\", \"messageFormatter\": \"Please do not use 'onclick' in HTML link.\", \"customValidatorContractName\": \"should_not_contain_onclick\", \"openingTagOnly\": true } ] } How to enable custom HTML tag rules Same as default HTML tag rule, config the rule in md.style . Create a folder ( rules for example) in your DocFX project folder, put all your custom rule assemblies to a plugins folder under rules folder. Now your DocFX project should look like this: / |- docfx.json |- md.style \\- rules \\- plugins \\- <your_rule>.dll Update your docfx.json with following content: { ... \"dest\": \"_site\", \"template\": [ \"default\", \"rules\" ] } Run docfx you'll see your rule being executed. The folder rules is actually a template folder. In DocFX, template is a place for you to customize build, render, validation behavior. For more information about template, please refer to our template and plugin documentation. Markdown token validation rules Besides HTML tags, you may also want to validate Markdown syntax like heading or links. For example, in Markdown, you may want to limit code snippet to only support a set of languages. To create such rule, follow the following steps: Create a project in your code editor (e.g. Visual Studio). Add nuget package Microsoft.DocAsCode.MarkdownLite and Microsoft.Composition . Create a class and implements @Microsoft.DocAsCode.MarkdownLite.IMarkdownTokenValidatorProvider > @Microsoft.DocAsCode.MarkdownLite.MarkdownTokenValidatorFactory contains some helper methods to create a validator. Add ExportAttribute with rule name. For example, the following rule require all code block to be csharp : [Export(\"code_snippet_should_be_csharp\", typeof(IMarkdownTokenValidatorProvider))] public class MyMarkdownTokenValidatorProvider : IMarkdownTokenValidatorProvider { public ImmutableArray<IMarkdownTokenValidator> GetValidators() { return ImmutableArray.Create( MarkdownTokenValidatorFactory.FromLambda<MarkdownCodeBlockToken>(t => { if (t.Lang != \"csharp\") { throw new DocumentException($\"Code lang {t.Lang} is not valid, in file: {t.SourceInfo.File}, at line: {t.SourceInfo.LineNumber}\"); } })); } } To enable this rule, update your md.style to the following: { \"rules\": [ \"code_snippet_should_be_csharp\" ] } Then follow the same steps in How to enable custom HTML tag rules , run docfx you'll see your rule executed. Logging in your rules As you can see in the above example, you can throw @Microsoft.DocAsCode.Plugins.DocumentException to raise an error, this will stop the build immediately. You can also use @Microsoft.DocAsCode.Common.Logger.LogWarning(System.String,System.String,System.String,System.String) and @Microsoft.DocAsCode.Common.Logger.LogError(System.String,System.String,System.String,System.String) to report a warning and an error respectively. To use these methods, you need to install nuget package Microsoft.DocAsCode.Common first. The different between ReportError and throw DocumentException is throwing exception will stop the build immediately but ReportError won't stop build but will eventually fail the build after rules are run. Advanced: validating tokens with file context For some cases, we need to validate some tokens with file context. For example, we want each topic has one title (i.e. h1 written by markdown syntax, e.g. # <title> ). But you cannot count them in @Microsoft.DocAsCode.MarkdownLite.IMarkdownTokenValidator, it is shared by all files, and it will never be hit when there is no heading. For this purpose, we need to create validator like following: MarkdownTokenValidatorFactory.FromLambda<MarkdownHeadingBlockToken>( t => { if (t.Depth == 1) { var re = MarkdownTokenValidatorContext.CurrentRewriteEngine; var h1Count = (int)re.GetVariable(\"h1Count\"); re.SetVariable(\"h1Count\", h1Count + 1); } }, re => { re.SetVariable(\"h1Count\", 0); re.SetPostProcess(\"checkH1Count\", re1 => { var h1Count = (int)re.GetVariable(\"h1Count\"); if (h1Count != 1) { Logger.LogError($\"Unexpected title count: {h1Count}.\"); } }) }); The FromLambda method takes two callbacks: The first will be invoked on @Microsoft.DocAsCode.MarkdownLite.MarkdownHeadingBlockToken matched in all files. And the static property @Microsoft.DocAsCode.MarkdownLite.MarkdownTokenValidatorContext.CurrentRewriteEngine will provide current context object. The second will be invoked on starting a new file. And you can initialize some variables for each file, and register some callbacks when the file completed. Advanced usage of md.style Default rules If a rule has the contract name of default , it will be enabled by default. You don't need to enable it in md.style . Enable/disable rules in md.style You can add use disable to specify whether disable a rule: { \"rules\": [ { \"contractName\": \"<contract_name>\", \"disable\": true } ] } This gives you an opportunity to disable the rules enabled by default. Validate metadata in markdown files In markdown file, we can write some metadata in conceptual or overwrite document . And we allow to add some plug-ins to validate metadata written in markdown files. Scope of metadata validation Metadata is coming from multiple sources, the following metadata will be validated during build: YAML header in markdown. Global metadata and file metaata in docfx.json . Global metadata and file metadata defined in separate .json files. For more information about global metadata and global metadata, see docfx.json format . Create validation plug-ins Create a project in your code editor (e.g. Visual Studio). Add nuget package Microsoft.DocAsCode.Plugins and Microsoft.Composition . Create a class and implement @Microsoft.DocAsCode.Plugins.IInputMetadataValidator For example, the following validator prohibits any metadata with name hello : [Export(typeof(IInputMetadataValidator))] public class MyInputMetadataValidator : IInputMetadataValidator { public void Validate(string sourceFile, ImmutableDictionary<string, object> metadata) { if (metadata.ContainsKey(\"hello\")) { throw new DocumentException($\"Metadata 'hello' is not allowed, file: {sourceFile}\"); } } } Enable metadata rule is same as other rules, just copy the assemblies to the plugins of your template folder and run docfx . Create configurable metadata validation plug-ins There are two steps to create a metadata validator: We need to modify export attribute for metadata validator plug-in: [Export(\"hello_is_not_valid\", typeof(IInputMetadataValidator))] Note If the rule doesn't have a contract name, it will be always enabled, i.e., there is no way to disable it unless delete the assembly file. Modify md.style with following content: { \"metadataRules\": [ { \"contractName\": \"hello_is_not_valid\", \"disable\": false } ] } Advanced: Share your rules Some users have a lot of document projects, and want to share validations for all of them, and don't want to write md.style file repeatedly. Create template For this propose, we can create a template with following structure: / (root folder for plug-in) \\- md.styles |- <category-1>.md.style \\- <category-2>.md.style \\- plugins \\- <your_rule>.dll In md.styles folder, there is a set of definition files, with file extension .md.style , each file is a category. In one category, there is a set of rule definition. For example, create a file with name test.md.style , then write following content: { \"tagRules\": { \"heading\": { \"tagNames\": [ \"H1\", \"H2\" ], \"behavior\": \"Warning\", \"messageFormatter\": \"Please do not use <H1> and <H2>, use '#' and '##' instead.\", \"openingTagOnly\": true } }, \"rules\": { \"code\": \"code_snippet_should_be_csharp\" }, \"metadataRules\": { \"hello\": { \"contractName\": \"hello_is_not_valid\", \"disable\": true } } } Then test is the category name (from file name) for three rules, and apply different id for each rule, they are heading , code and hello . When you build document with this template, all rules will be active when disable property is false . Config rules Some rules need to be enabled/disabled in some special document project. For example, hello rule is not required for most project, but for a special project, we want to enable it. We need to modify md.style file in this document project with following content: { \"settings\": [ { \"category\": \"test\", \"id\": \"hello\", \"disable\": false } ] } And for some project we need to disable all rules in test category: { \"settings\": [ { \"category\": \"test\", \"disable\": true } ] } Note disable property is applied by following order: tagRules , rules and metadataRules in md.style . auto enabled rules with contract name default . settings with category and id in md.style . settings with category in md.style . disable property in definition file."
  }
}